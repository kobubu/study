{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e417b334",
   "metadata": {},
   "source": [
    "# Лекция 5: \n",
    "\n",
    "# Практика — Оконные функции и векторизация текста\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5fa01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, length, split, size, substring, countDistinct, min, max, avg\n",
    "from pyspark.sql.functions import sqrt\n",
    "from pyspark.sql.functions import when\n",
    "import time\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Stable_Spark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51337daa",
   "metadata": {},
   "source": [
    "###  Загрузка данных из Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "384b8f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено из: data/processed/reviews.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество записей: 109,998\n",
      "Все ключевые колонки присутствуют: ['review_text', 'sentiment', 'film_id', 'review_num']\n",
      "Схема данных для лекции 5:\n",
      "root\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- file_path: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- film_id: integer (nullable = true)\n",
      " |-- review_num: integer (nullable = true)\n",
      " |-- review_length: integer (nullable = true)\n",
      " |-- word_count: integer (nullable = true)\n",
      "\n",
      "\n",
      "Пример данных с признаками film_id и review_num:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-------------+------------------------------+\n",
      "|film_id|review_num|sentiment|review_length|preview                       |\n",
      "+-------+----------+---------+-------------+------------------------------+\n",
      "|306    |1         |pos      |1722         |Фильмы начала 2000-годов всегд|\n",
      "|306    |2         |pos      |999          |К студенту Джеймсу Клейтону об|\n",
      "|306    |3         |pos      |1230         |Я симпатизирую Роджеру Дональд|\n",
      "|306    |4         |neu      |3345         |С фильмом 'Рекрут' (The Recrui|\n",
      "|306    |5         |pos      |926          |После первого просмотра фильма|\n",
      "+-------+----------+---------+-------------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Статистика по новым признакам:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 190:====================================================>(121 + 2) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Уникальных фильмов: 9,065\n",
      "  Диапазон номеров рецензий: 1 - 99\n",
      "  Средняя длина отзыва: 2042.8 символов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "PARQUET_PATH = \"data/processed/reviews.parquet\"\n",
    "\n",
    "df = spark.read.parquet(PARQUET_PATH)\n",
    "print(f\"Загружено из: {PARQUET_PATH}\")\n",
    "print(f\"Количество записей: {df.count():,}\")\n",
    "    \n",
    "required_cols = ['review_text', 'sentiment', 'film_id', 'review_num']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Внимание: отсутствуют колонки {missing_cols}\")\n",
    "    print(\"   Проверьте, что Лекция 4 выполнена полностью\")\n",
    "else:\n",
    "    print(f\"Все ключевые колонки присутствуют: {required_cols}\")\n",
    "    \n",
    "if 'review_length' not in df.columns:\n",
    "    df = df.withColumn('review_length', length(col('review_text')))\n",
    "    print(\"Добавлена колонка: review_length\")\n",
    "    \n",
    "if 'word_count' not in df.columns:\n",
    "    df = df.withColumn('word_count', size(split(col('review_text'), '\\\\s+')))\n",
    "    print(\"Добавлена колонка: word_count\")\n",
    "    \n",
    "print(\"Схема данных для лекции 5:\")\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\nПример данных с признаками film_id и review_num:\")\n",
    "df.select(\"film_id\", \"review_num\", \"sentiment\", \n",
    "              \"review_length\", substring(\"review_text\", 1, 30).alias(\"preview\")) \\\n",
    "      .orderBy(\"film_id\", \"review_num\") \\\n",
    "      .show(5, truncate=False)\n",
    "\n",
    "print(\"\\nСтатистика по новым признакам:\")\n",
    "stats = df.agg(\n",
    "        countDistinct(\"film_id\").alias(\"unique_films\"),\n",
    "        min(\"review_num\").alias(\"min_review_num\"),\n",
    "        max(\"review_num\").alias(\"max_review_num\"),\n",
    "        avg(\"review_length\").alias(\"avg_length\")\n",
    "        ).collect()[0]\n",
    "    \n",
    "print(f\"  Уникальных фильмов: {stats['unique_films']:,}\")\n",
    "print(f\"  Диапазон номеров рецензий: {stats['min_review_num']} - {stats['max_review_num']}\")\n",
    "print(f\"  Средняя длина отзыва: {stats['avg_length']:.1f} символов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956bef6",
   "metadata": {},
   "source": [
    "### Часть 1. Оконные функции: анализ внутри групп без потери деталей\n",
    "\n",
    "Ключевая концепция: \n",
    "\n",
    "В отличие от `GROUP BY`, который агрегирует данные и схлопывает строки, оконные функции позволяют выполнять вычисления над группой связанных строк (окном), сохраняя при этом каждую исходную строку нетронутой. Это идеально для анализа трендов, ранжирования и сравнений.\n",
    "\n",
    "| Компонент окна | Описание | Пример на наших данных |\n",
    "| :--- | :--- | :--- |\n",
    "| Partition (`PARTITION BY`) | Разбивает данные на логические группы для независимых вычислений. | `PARTITION BY sentiment` — отдельные окна для `neg`, `pos`, `neu`. |\n",
    "| Order (`ORDER BY`) | Определяет порядок строк внутри каждого раздела (партиции). | `ORDER BY review_length DESC` — сортировка от длинных к коротким отзывам. |\n",
    "| Frame | Определяет, какие строки внутри партиции участвуют в расчете для текущей строки (например, \"2 строки до текущей\"). | `.rowsBetween(-2, 0)` — окно из трех строк: текущая и две предыдущие. |\n",
    "\n",
    "Пример создания спецификации окна в PySpark:\n",
    "```python\n",
    "from pyspark.sql.window import Window\n",
    "# Окно для ранжирования по длине отзыва внутри каждой тональности\n",
    "window_spec = Window.partitionBy(\"sentiment\").orderBy(col(\"review_length\").desc())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0e21b",
   "metadata": {},
   "source": [
    "### Проблема традиционных GROUP BY\n",
    "\n",
    "```\n",
    "ТРАДИЦИОННЫЙ GROUP BY:\n",
    "┌─────────────┬────────────┐\n",
    "│ sentiment   │ avg_length │\n",
    "├─────────────┼────────────┤\n",
    "│ neg         │ 245.6      │\n",
    "│ pos         │ 312.8      │\n",
    "│ neu         │ 198.4      │\n",
    "└─────────────┴────────────┘\n",
    "\n",
    "ЧТО ТЕРЯЕМ?\n",
    "• Конкретные отзывы внутри групп\n",
    "• Индивидуальные характеристики\n",
    "• Возможность сравнения с групповыми метриками\n",
    "```\n",
    "\n",
    "Проблема: `GROUP BY` схлопывает данные, теряя детализацию. Мы получаем только агрегированные значения без возможности анализа отдельных записей.\n",
    "\n",
    "###  Решение - оконные функции (Window Functions)\n",
    "\n",
    "```\n",
    "ОКОННЫЕ ФУНКЦИИ СОХРАНЯЮТ ДЕТАЛИЗАЦИЮ:\n",
    "╔══════════╦════════════╦═══════════╦═══════════════════════════════════════╗\n",
    "║ film_id  ║ review_num ║ sentiment ║ review_length ║ avg_in_group ║ rank ║\n",
    "╠══════════╬════════════╬═══════════╬═══════════════╬═══════════════╬══════╣\n",
    "║ 102      ║ 1          ║ pos       ║ 256           ║ 312.8         ║ 15   ║\n",
    "║ 102      ║ 2          ║ pos       ║ 345           ║ 312.8         ║ 8    ║\n",
    "║ 102      ║ 3          ║ pos       ║ 289           ║ 312.8         ║ 12   ║\n",
    "║ 203      ║ 1          ║ neg       ║ 198           ║ 245.6         ║ 22   ║\n",
    "╚══════════╩════════════╩═══════════╩═══════════════╩═══════════════╩══════╝\n",
    "\n",
    "ПРЕИМУЩЕСТВА:\n",
    "✓ Сохраняются все исходные строки\n",
    "✓ Добавляются групповые метрики\n",
    "✓ Возможность ранжирования внутри групп\n",
    "✓ Сравнение с групповыми средними\n",
    "```\n",
    "\n",
    "Ключевая концепция: Оконные функции выполняют вычисления над группой связанных строк (окном), сохраняя каждую исходную строку нетронутой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b673b",
   "metadata": {},
   "source": [
    "### Архитектура оконной функции - три компонента\n",
    "\n",
    "```\n",
    "ОКНО = PARTITION  +  ORDER   +   FRAME\n",
    "          ↓            ↓         ↓\n",
    "      Разбиваем   Сортируем   Определяем границы\n",
    "```\n",
    "\n",
    "#### Компонент 1: PARTITION BY (разбиение)\n",
    "```\n",
    "ЧТО ДЕЛАЕТ:\n",
    "Разбивает данные на логические группы для независимых вычислений\n",
    "\n",
    "ПРАКТИЧЕСКИЙ ПРИМЕР НА НАШИХ ДАННЫХ:\n",
    "• PARTITION BY sentiment → отдельные окна для neg, pos, neu\n",
    "• PARTITION BY film_id → анализ внутри каждого фильма\n",
    "• PARTITION BY film_id, sentiment → комбинированное разбиение\n",
    "\n",
    "ВИЗУАЛИЗАЦИЯ:\n",
    "Данные → [neg отзывы] [pos отзывы] [neu отзывы]\n",
    "             ↓             ↓            ↓\n",
    "         Окно 1        Окно 2       Окно 3\n",
    "```\n",
    "\n",
    "#### Компонент 2: ORDER BY (упорядочивание)\n",
    "```\n",
    "ЧТО ДЕЛАЕТ:\n",
    "Определяет порядок строк внутри каждого раздела (партиции)\n",
    "\n",
    "ПРАКТИЧЕСКИЙ ПРИМЕР НА НАШИХ ДАННЫХ:\n",
    "• ORDER BY review_length DESC → от длинных к коротким\n",
    "• ORDER BY review_num ASC → по порядку рецензий\n",
    "• ORDER BY review_date DESC → от новых к старым\n",
    "\n",
    "ЗАЧЕМ НУЖНО:\n",
    "1. Для ранжирующих функций (row_number, rank)\n",
    "2. Для функций сдвига (lag, lead)\n",
    "3. Для определения порядка в скользящих окнах\n",
    "```\n",
    "\n",
    "#### Компонент 3: FRAME (границы окна)\n",
    "```\n",
    "ЧТО ДЕЛАЕТ:\n",
    "Определяет, какие строки внутри партиции участвуют в расчете\n",
    "для текущей строки\n",
    "\n",
    "ТИПЫ ФРЕЙМОВ:\n",
    "1. ROWS BETWEEN - физические строки\n",
    "   • .rowsBetween(-2, 0) → текущая + 2 предыдущие\n",
    "   • .rowsBetween(Window.unboundedPreceding, 0) → все предыдущие\n",
    "\n",
    "2. RANGE BETWEEN - логические значения\n",
    "   • .rangeBetween(-100, 100) → значения в диапазоне ±100\n",
    "\n",
    "ПРАКТИЧЕСКИЙ ПРИМЕР:\n",
    "• Для скользящего среднего: .rowsBetween(-2, 0)\n",
    "• Для накопительной суммы: .rowsBetween(Window.unboundedPreceding, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d836aae",
   "metadata": {},
   "source": [
    "###  Сравнение оконных функций с другими подходами\n",
    "\n",
    "```\n",
    "СРАВНИТЕЛЬНАЯ ТАБЛИЦА:\n",
    "\n",
    "| Подход              | Сохраняет строки | Групповые метрики | Сравнение строк | Производительность |\n",
    "|---------------------|------------------|-------------------|-----------------|--------------------|\n",
    "| GROUP BY            | Нет              | Да                | Нет             | Высокая            |\n",
    "| JOIN с агрегатами   | Да               | Да                | Ограниченно     | Средняя            |\n",
    "| Оконные функции     | Да               | Да                | Полностью       | Зависит от окна    |\n",
    "| UDF (Python)        | Да               | Нет               | Нет             | Низкая             |\n",
    "\n",
    "ПРЕИМУЩЕСТВА ОКОННЫХ ФУНКЦИЙ:\n",
    "1. Эффективность: вычисления в рамках одного прохода по данным\n",
    "2. Гибкость: различные типы окон и функций\n",
    "3. Читаемость: декларативный SQL-подобный синтаксис\n",
    "4. Оптимизация: Catalyst оптимизирует оконные вычисления\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846ebfb",
   "metadata": {},
   "source": [
    "### Часть 2. Типы оконных функций и их применение для анализа отзывов\n",
    "\n",
    "В практике вы будете использовать несколько ключевых типов функций.\n",
    "\n",
    "1. Ранжирующие функции\n",
    "Эти функции присваивают порядковый номер строке внутри ее партиции.\n",
    "*   `row_number()`: Присваивает уникальный номер строке (1, 2, 3...). Даже если значения в столбце сортировки совпадают, номера будут разными. *Используется для выбора топ-N записей (например, 3 самых длинных отзыва в каждой категории).*\n",
    "*   `rank()`: Присваивает одинаковый ранг одинаковым значениям, но оставляет \"пропуски\" в нумерации (1, 1, 3...).\n",
    "*   `dense_rank()`: Как `rank()`, но без пропусков в нумерации (1, 1, 2...).\n",
    "\n",
    "2. Аналитические функции (сдвига)\n",
    "Позволяют сравнивать значения из разных строк.\n",
    "*   `lag()`: Получает значение из предыдущей строки в рамках партиции. *Пример: сравнить длину текущего отзыва с предыдущим того же пользователя.*\n",
    "*   `lead()`: Получает значение из следующей строки.\n",
    "\n",
    "3. Агрегатные функции в окне\n",
    "Позволяют рассчитать агрегаты (сумму, среднее) по окну, а не по всему датасету.\n",
    "*   `sum()`, `avg()`, `min()`, `max()`: *Пример: `avg(review_length) OVER (PARTITION BY sentiment)` — добавит в каждую строку среднюю длину отзывов по ее тональности.*\n",
    "*   Скользящее окно: Агрегация по динамическому окну (например, \"последние 3 отзыва\") задается фреймом `.rowsBetween(-2, 0)`.\n",
    "*   Накопительный итог: Для расчета используйте фрейм `.rowsBetween(Window.unboundedPreceding, Window.currentRow)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2ae94",
   "metadata": {},
   "source": [
    "##  Классификация оконных функций\n",
    "\n",
    "```\n",
    "ТРИ ОСНОВНЫХ КАТЕГОРИИ ОКОННЫХ ФУНКЦИЙ:\n",
    "\n",
    "1. РАНЖИРУЮЩИЕ ФУНКЦИИ\n",
    "   Назначение: упорядочивание строк внутри партиции\n",
    "   Примеры: row_number(), rank(), dense_rank(), ntile()\n",
    "\n",
    "2. АНАЛИТИЧЕСКИЕ ФУНКЦИИ (СДВИГА)\n",
    "   Назначение: сравнение с соседними строками\n",
    "   Примеры: lag(), lead(), first_value(), last_value()\n",
    "\n",
    "3. АГРЕГАТНЫЕ ФУНКЦИИ В ОКНЕ\n",
    "   Назначение: вычисление статистик по группе\n",
    "   Примеры: sum(), avg(), min(), max(), count()\n",
    "\n",
    "ОБЩИЙ ПРИНЦИП:\n",
    "Все эти функции работают НАД окном, но не изменяют исходные данные\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa15af4",
   "metadata": {},
   "source": [
    "## Ранжирующие функции - визуальное сравнение\n",
    "\n",
    "### row_number() vs rank() vs dense_rank()\n",
    "\n",
    "```\n",
    "ИСХОДНЫЕ ДАННЫЕ (отсортированы по review_length DESC):\n",
    "film_id | review_num | review_length | sentiment\n",
    "--------|------------|---------------|-----------\n",
    "102     | 5          | 450           | pos\n",
    "102     | 3          | 450           | pos    ← одинаковые значения\n",
    "102     | 1          | 380           | neg\n",
    "102     | 2          | 380           | neg    ← одинаковые значения\n",
    "102     | 4          | 290           | neu\n",
    "\n",
    "РЕЗУЛЬТАТЫ РАНЖИРОВАНИЯ:\n",
    "row_number()        rank()           dense_rank()\n",
    "----------------    --------------   ----------------\n",
    "1 (450) ←          1 (450) ←         1 (450) ←\n",
    "2 (450)            1 (450)           1 (450)\n",
    "3 (380)            3 (380) ←         2 (380) ←\n",
    "4 (380)            3 (380)           2 (380)\n",
    "5 (290)            5 (290)           3 (290)\n",
    "\n",
    "КЛЮЧЕВЫЕ ОТЛИЧИЯ:\n",
    "• row_number(): Всегда уникальные номера (1, 2, 3, 4, 5)\n",
    "• rank():       Пропуски при одинаковых значениях (1, 1, 3, 3, 5)\n",
    "• dense_rank(): Без пропусков (1, 1, 2, 2, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85b469",
   "metadata": {},
   "source": [
    "##  Аналитические функции сдвига - lag() и lead()\n",
    "\n",
    "```\n",
    "КОНЦЕПЦИЯ \"ОКНА ВРЕМЕНИ\":\n",
    "Текущая строка имеет доступ к соседним строкам в рамках партиции\n",
    "\n",
    "    [предыдущая] ← lag(1)   [ТЕКУЩАЯ]   lead(1) → [следующая]\n",
    "    [2 строки назад] ← lag(2)           lead(2) → [через 2 строки]\n",
    "\n",
    "СИНТАКСИС:\n",
    "lag(column, offset, default_value)  # offset - на сколько строк назад\n",
    "lead(column, offset, default_value) # offset - на сколько строк вперед\n",
    "\n",
    "ПРИМЕР НА НАШИХ ДАННЫХ:\n",
    "Окно: Window.partitionBy(\"film_id\").orderBy(\"review_num\")\n",
    "\n",
    "Исходные данные:\n",
    "review_num | review_length | sentiment\n",
    "-----------|---------------|----------\n",
    "1          | 256           | pos\n",
    "2          | 345           | neg      ← текущая строка\n",
    "3          | 289           | pos\n",
    "\n",
    "Результат для строки 2:\n",
    "lag(\"review_length\", 1)    = 256    (значение из строки 1)\n",
    "lag(\"sentiment\", 1)        = \"pos\"  (sentiment из строки 1)\n",
    "lead(\"review_length\", 1)   = 289    (значение из строки 3)\n",
    "lead(\"sentiment\", 1)       = \"pos\"  (sentiment из строки 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82be6f",
   "metadata": {},
   "source": [
    "## Агрегатные функции в окне - базовые агрегаты\n",
    "\n",
    "```\n",
    "ОТЛИЧИЕ ОТ ГРУППИРОВКИ:\n",
    "GROUP BY:                 ОКОННЫЕ ФУНКЦИИ:\n",
    "[схлопывает строки]      [сохраняет все строки]\n",
    "┌─────┬──────┐           ╔══════╦══════╦═══════════╗\n",
    "│ cat │ avg  │           ║ id   ║ cat  ║ avg_in_cat║\n",
    "├─────┼──────┤           ╠══════╬══════╬═══════════╣\n",
    "│ A   │ 25.6 │           ║ 1    ║ A    ║ 25.6      ║\n",
    "│ B   │ 32.1 │           ║ 2    ║ A    ║ 25.6      ║\n",
    "└─────┴──────┘           ║ 3    ║ B    ║ 32.1      ║\n",
    "                         ║ 4    ║ B    ║ 32.1      ║\n",
    "                         ╚══════╩══════╩═══════════╝\n",
    "\n",
    "ПРИМЕР НА НАШИХ ДАННЫХ:\n",
    "# Средняя длина отзывов по каждой тональности\n",
    "window_sentiment = Window.partitionBy(\"sentiment\")\n",
    "df = df.withColumn(\"avg_length_by_sentiment\", \n",
    "                  avg(\"review_length\").over(window_sentiment))\n",
    "\n",
    "# Количество отзывов по каждому фильму\n",
    "window_film = Window.partitionBy(\"film_id\")\n",
    "df = df.withColumn(\"reviews_per_film\", \n",
    "                  count(\"*\").over(window_film))\n",
    "\n",
    "РЕЗУЛЬТАТ КАЖДОЙ СТРОКИ:\n",
    "film_id | sentiment | review_length | avg_length_by_sentiment | reviews_per_film\n",
    "--------|-----------|---------------|-------------------------|-----------------\n",
    "102     | pos       | 450           | 312.8 (среднее по pos)  | 15 (всего отзывов о фильме 102)\n",
    "102     | pos       | 380           | 312.8 (среднее по pos)  | 15\n",
    "203     | neg       | 290           | 245.6 (среднее по neg)  | 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978e783",
   "metadata": {},
   "source": [
    "## Типы окон для агрегатов - фреймы\n",
    "\n",
    "### Три основных типа фреймов:\n",
    "\n",
    "1. ПОЛНАЯ ПАРТИЦИЯ (по умолчанию)  \n",
    "   `.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)`  \n",
    "   Все строки партиции участвуют в расчете  \n",
    "   Пример: общее среднее по всей категории  \n",
    "\n",
    "2. НАКОПИТЕЛЬНЫЙ ИТОГ (CUMULATIVE)  \n",
    "   `.rowsBetween(Window.unboundedPreceding, Window.currentRow)`  \n",
    "   Все ПРЕДЫДУЩИЕ строки + текущая  \n",
    "   Пример: running total, cumulative average  \n",
    "\n",
    "3. СКОЛЬЗЯЩЕЕ ОКНО (SLIDING/ROLLING)  \n",
    "   `.rowsBetween(-2, 0)`    # 3 строки: текущая + 2 предыдущих  \n",
    "   `.rowsBetween(-1, 1)`    # 3 строки: предыдущая + текущая + следующая  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ceba40",
   "metadata": {},
   "source": [
    "## Накопительные агрегаты - cumulative window\n",
    "\n",
    "КОНЦЕПЦИЯ: \"Вычисления нарастающим итогом\"\n",
    "\n",
    "ПРИМЕР: Кумулятивная сумма длин отзывов по фильму\n",
    "\n",
    "ОКНО:\n",
    "```python\n",
    "Window.partitionBy(\"film_id\")\n",
    "      .orderBy(\"review_num\")\n",
    "      .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "```\n",
    "\n",
    "ДАННЫЕ:\n",
    "review_num | review_length | cumulative_sum\n",
    "-----------|---------------|---------------\n",
    "1          | 256           | 256     ← 256\n",
    "2          | 345           | 601     ← 256 + 345\n",
    "3          | 289           | 890     ← 256 + 345 + 289\n",
    "4          | 320           | 1210    ← 256 + 345 + 289 + 320\n",
    "\n",
    "ПРАКТИЧЕСКОЕ ПРИМЕНЕНИЕ:\n",
    "1. Накопительное количество: count(*).over(cumulative_window)\n",
    "2. Бегущее среднее: avg(column).over(cumulative_window)\n",
    "3. Доля от общей суммы: column / sum(column).over(full_window)\n",
    "\n",
    "КОД ДЛЯ НАШИХ ДАННЫХ:\n",
    "\n",
    "```python\n",
    "# Накопительная статистика по фильмам\n",
    "cumulative_window = Window.partitionBy(\"film_id\") \\\n",
    "                         .orderBy(\"review_num\") \\\n",
    "                         .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "df_cumulative = df.withColumn(\"running_total\", sum(\"review_length\").over(cumulative_window)) \\\n",
    "                  .withColumn(\"running_avg\", avg(\"review_length\").over(cumulative_window)) \\\n",
    "                  .withColumn(\"running_count\", count(\"*\").over(cumulative_window))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd1187",
   "metadata": {},
   "source": [
    "##  Скользящие агрегаты - rolling window\n",
    "\n",
    "КОНЦЕПЦИЯ: \"Окно фиксированного размера, скользящее по данным\"\n",
    "\n",
    "ПРИМЕР: Скользящее среднее по 3 последним отзывам\n",
    "\n",
    "ОКНО:\n",
    "```python\n",
    "Window.partitionBy(\"film_id\")\n",
    "      .orderBy(\"review_num\")\n",
    "      .rowsBetween(-2, 0)  # Текущая + 2 предыдущих\n",
    "```\n",
    "\n",
    "ДАННЫЕ:\n",
    "review_num | review_length | rolling_avg_3\n",
    "-----------|---------------|--------------\n",
    "1          | 256           | 256.0    ← (256)/1\n",
    "2          | 345           | 300.5    ← (256 + 345)/2\n",
    "3          | 289           | 296.7    ← (256 + 345 + 289)/3\n",
    "4          | 320           | 318.0    ← (345 + 289 + 320)/3\n",
    "5          | 310           | 306.3    ← (289 + 320 + 310)/3\n",
    "\n",
    "ВИДЫ СКОЛЬЗЯЩИХ ОКОН:\n",
    "1. Симметричное: .rowsBetween(-1, 1)  # предыдущая + текущая + следующая\n",
    "2. Только назад: .rowsBetween(-3, 0)   # 4 последних (текущая + 3 предыдущих)\n",
    "3. Только вперед: .rowsBetween(0, 2)   # 3 следующих (текущая + 2 следующих)\n",
    "\n",
    "ПРАКТИЧЕСКОЕ ПРИМЕНЕНИЕ:  \n",
    "• Сглаживание временных рядов  \n",
    "• Обнаружение трендов  \n",
    "• Фильтрация шума в данных  \n",
    "• Анализ краткосрочных паттернов  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f980f",
   "metadata": {},
   "source": [
    "## Сводная таблица применения функций для анализа отзывов\n",
    "\n",
    "```\n",
    "| Функция        | Тип          | Практическое применение для отзывов              | Пример использования                           |\n",
    "|----------------|--------------|--------------------------------------------------|------------------------------------------------|\n",
    "| row_number()   | Ранжирующая  | Топ-3 самых длинных отзывов по фильму            | .filter(col(\"rank\") <= 3)                      |\n",
    "| rank()         | Ранжирующая  | Рейтинг фильмов по средней оценке с пропусками   | Анализ при равных средних значениях            |\n",
    "| dense_rank()   | Ранжирующая  | Группировка фильмов по \"уровню\" популярности     | Категоризация (популярные/средние/непопулярные)|\n",
    "| lag()          | Аналитическая| Сравнение отзыва с предыдущим того же автора     | Анализ эволюции мнения                         |\n",
    "| lead()         | Аналитическая| Предсказание следующей тональности по паттернам  | Обнаружение трендов                            |\n",
    "| avg()          | Агрегатная   | Средняя длина отзывов по жанру                   | Сравнение сложности отзывов между жанрами      |\n",
    "| sum()          | Агрегатная   | Общий объем текста по фильму                     | Оценка \"обсуждаемости\" фильма                  |\n",
    "| count()        | Агрегатная   | Количество отзывов за период                     | Анализ активности пользователей                |\n",
    "| min()/max()    | Агрегатная   | Диапазон длин отзывов по категории               | Обнаружение аномалий/выбросов                  |\n",
    "\n",
    "КОМБИНИРОВАННЫЕ СЦЕНАРИИ:\n",
    "1. Сначала rank() для определения позиции\n",
    "2. Затем lag() для сравнения с предыдущим\n",
    "3. Наконец avg() в скользящем окне для сглаживания\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59c0b6",
   "metadata": {},
   "source": [
    "### Создание оконных спецификаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "599e4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, rank, dense_rank, lag, lead, \\\n",
    "                                  avg, sum, count, stddev, min, max, first_value, last_value\n",
    "\n",
    "# 1. окно для анализа последовательности отзывов по фильмам\n",
    "window_film_seq = Window.partitionBy(\"film_id\").orderBy(\"review_num\")\n",
    "\n",
    "# 2. окно для ранжирования отзывов по длине внутри тональности\n",
    "window_rank_sentiment = Window.partitionBy(\"sentiment\").orderBy(col(\"review_length\").desc())\n",
    "\n",
    "# 3. окно для агрегации без сортировки\n",
    "window_agg_sentiment = Window.partitionBy(\"sentiment\")\n",
    "\n",
    "# 4. скользящее окно для трендов\n",
    "window_sliding = Window.partitionBy(\"film_id\") \\\n",
    "                       .orderBy(\"review_num\") \\\n",
    "                       .rowsBetween(-2, 0)  # текущая + 2 предыдущих\n",
    "\n",
    "# 5. накопительное окно\n",
    "window_cumulative = Window.partitionBy(\"film_id\") \\\n",
    "                         .orderBy(\"review_num\") \\\n",
    "                         .rowsBetween(Window.unboundedPreceding, Window.currentRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeaee3e",
   "metadata": {},
   "source": [
    "###  Ранжирующие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d25bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Ранжирование отзывов по длине внутри каждой тональности:\n",
      "\n",
      "   Тональность 'pos':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------+----+----------+\n",
      "|film_id|review_num|review_length|row_num|rank|dense_rank|\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "|778218 |10        |5000         |1      |1   |1         |\n",
      "|195434 |96        |5000         |2      |1   |1         |\n",
      "|102740 |10        |5000         |3      |1   |1         |\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "\n",
      "\n",
      "   Тональность 'neg':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------+----+----------+\n",
      "|film_id|review_num|review_length|row_num|rank|dense_rank|\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "|1176159|8         |5000         |1      |1   |1         |\n",
      "|22500  |2         |4996         |2      |2   |2         |\n",
      "|423063 |40        |4995         |3      |3   |3         |\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "\n",
      "\n",
      "   Тональность 'neu':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 202:===============================================>    (113 + 10) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------+----+----------+\n",
      "|film_id|review_num|review_length|row_num|rank|dense_rank|\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "|260898 |80        |5000         |1      |1   |1         |\n",
      "|521607 |24        |4998         |2      |2   |2         |\n",
      "|661911 |35        |4997         |3      |3   |3         |\n",
      "+-------+----------+-------------+-------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# применение: row_number(), rank(), dense_rank()\n",
    "print(\"\\n1. Ранжирование отзывов по длине внутри каждой тональности:\")\n",
    "\n",
    "df_ranked = df.withColumn(\"row_num\", row_number().over(window_rank_sentiment)) \\\n",
    "              .withColumn(\"rank\", rank().over(window_rank_sentiment)) \\\n",
    "              .withColumn(\"dense_rank\", dense_rank().over(window_rank_sentiment))\n",
    "\n",
    "# примеры для каждой тональности\n",
    "for sentiment in [\"pos\", \"neg\", \"neu\"]:\n",
    "    print(f\"\\n   Тональность '{sentiment}':\")\n",
    "    sample = df_ranked.filter(col(\"sentiment\") == sentiment) \\\n",
    "                     .select(\"film_id\", \"review_num\", \"review_length\", \n",
    "                             \"row_num\", \"rank\", \"dense_rank\") \\\n",
    "                     .orderBy(\"row_num\") \\\n",
    "                     .limit(3)\n",
    "    sample.show(truncate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db5d6f",
   "metadata": {},
   "source": [
    "   Объяснение различий функций:\n",
    "\n",
    "   • row_number() - всегда уникальные номера (1, 2, 3, 4, 5)  \n",
    "   • rank() - одинаковые ранги при равных значениях, с пропусками (1, 1, 3, 3, 5)  \n",
    "   • dense_rank() - одинаковые ранги без пропусков (1, 1, 2, 2, 3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe55c01",
   "metadata": {},
   "source": [
    "###  Аналитические функции сдвига\n",
    "\n",
    "   • Как часто меняется тональность?  \n",
    "   • Есть ли тренд в длине отзывов?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34bc4ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Анализ последовательности отзывов в фильме:\n",
      "   Использованные функции:\n",
      "   • lag(review_length, 1) - длина предыдущего отзыва\n",
      "   • lead(review_length, 1) - длина следующего отзыва\n",
      "   • lag(sentiment, 1) - тональность предыдущего отзыва\n",
      "   • lead(sentiment, 1) - тональность следующего отзыва\n",
      "\n",
      "   Пример для фильма ID=306:\n",
      "+-------+----------+---------+-------------+-----------+-----------+--------------+--------------+-------------+\n",
      "|film_id|review_num|sentiment|review_length|prev_length|next_length|prev_sentiment|next_sentiment|length_change|\n",
      "+-------+----------+---------+-------------+-----------+-----------+--------------+--------------+-------------+\n",
      "|306    |1         |pos      |1722         |NULL       |999        |NULL          |pos           |NULL         |\n",
      "|306    |2         |pos      |999          |1722       |1230       |pos           |pos           |-723         |\n",
      "|306    |3         |pos      |1230         |999        |3345       |pos           |neu           |231          |\n",
      "|306    |4         |neu      |3345         |1230       |926        |pos           |pos           |2115         |\n",
      "|306    |5         |pos      |926          |3345       |1970       |neu           |pos           |-2419        |\n",
      "+-------+----------+---------+-------------+-----------+-----------+--------------+--------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# lag() и lead() для анализа последовательности\n",
    "print(\"\\n2. Анализ последовательности отзывов в фильме:\")\n",
    "\n",
    "df_with_lag_lead = df.withColumn(\"prev_length\", lag(\"review_length\", 1).over(window_film_seq)) \\\n",
    "                     .withColumn(\"next_length\", lead(\"review_length\", 1).over(window_film_seq)) \\\n",
    "                     .withColumn(\"prev_sentiment\", lag(\"sentiment\", 1).over(window_film_seq)) \\\n",
    "                     .withColumn(\"next_sentiment\", lead(\"sentiment\", 1).over(window_film_seq)) \\\n",
    "                     .withColumn(\"length_change\", col(\"review_length\") - col(\"prev_length\"))\n",
    "\n",
    "print(\"   Использованные функции:\")\n",
    "print(\"   • lag(review_length, 1) - длина предыдущего отзыва\")\n",
    "print(\"   • lead(review_length, 1) - длина следующего отзыва\")\n",
    "print(\"   • lag(sentiment, 1) - тональность предыдущего отзыва\")\n",
    "print(\"   • lead(sentiment, 1) - тональность следующего отзыва\")\n",
    "\n",
    "print(\"\\n   Пример для фильма ID=306:\")\n",
    "film_example = df_with_lag_lead.filter(col(\"film_id\") == 306) \\\n",
    "                              .select(\"film_id\", \"review_num\", \"sentiment\", \n",
    "                                      \"review_length\", \"prev_length\", \"next_length\",\n",
    "                                      \"prev_sentiment\", \"next_sentiment\", \"length_change\") \\\n",
    "                              .orderBy(\"review_num\") \\\n",
    "                              .limit(5)\n",
    "film_example.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ced40d",
   "metadata": {},
   "source": [
    "###  Агрегатные функции в окне\n",
    "\n",
    "   Использованные функции:\n",
    "\n",
    "   • avg() - средняя длина отзывов по тональности  \n",
    "   • count() - количество отзывов по тональности  \n",
    "   • stddev() - разброс длин отзывов  \n",
    "   • min()/max() - минимальная/максимальная длина  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "474404c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Базовые агрегатные функции (групповые статистики):\n",
      "\n",
      "   Статистика по тональностям:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 208:========================================>            (94 + 12) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------+--------------------------+-----------------------+\n",
      "|sentiment|avg_length_in_sentiment|total_reviews_in_sentiment|std_length_in_sentiment|\n",
      "+---------+-----------------------+--------------------------+-----------------------+\n",
      "|neg      |2092.0192849014793     |16697                     |1045.0218599134985     |\n",
      "|pos      |2040.0542425363421     |72987                     |1051.288871516476      |\n",
      "|neu      |2012.4027764103573     |20314                     |1072.928410757921      |\n",
      "+---------+-----------------------+--------------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Базовые агрегатные функции (групповые статистики):\")\n",
    "\n",
    "df_with_aggregates = df.withColumn(\"avg_length_in_sentiment\", \n",
    "                                   avg(\"review_length\").over(window_agg_sentiment)) \\\n",
    "                       .withColumn(\"total_reviews_in_sentiment\", \n",
    "                                   count(\"*\").over(window_agg_sentiment)) \\\n",
    "                       .withColumn(\"std_length_in_sentiment\", \n",
    "                                   stddev(\"review_length\").over(window_agg_sentiment)) \\\n",
    "                       .withColumn(\"min_length_in_sentiment\", \n",
    "                                   min(\"review_length\").over(window_agg_sentiment)) \\\n",
    "                       .withColumn(\"max_length_in_sentiment\", \n",
    "                                   max(\"review_length\").over(window_agg_sentiment))\n",
    "\n",
    "print(\"\\n   Статистика по тональностям:\")\n",
    "stats_sample = df_with_aggregates.select(\"sentiment\", \"avg_length_in_sentiment\",\n",
    "                                        \"total_reviews_in_sentiment\", \"std_length_in_sentiment\") \\\n",
    "                                .distinct() \\\n",
    "                                .orderBy(\"avg_length_in_sentiment\", ascending=False)\n",
    "stats_sample.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ea44346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Скользящие агрегаты (скользящее окно):\n",
      "   Скользящее среднее по 3 последним отзывам в фильме:\n",
      "\n",
      "   Пример для фильма ID=306:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 211:====================================>                (84 + 12) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+------------------+-------------+---------------+\n",
      "|film_id|review_num|review_length|rolling_avg_3     |rolling_sum_3|rolling_count_3|\n",
      "+-------+----------+-------------+------------------+-------------+---------------+\n",
      "|306    |1         |1722         |1722.0            |1722         |1              |\n",
      "|306    |2         |999          |1360.5            |2721         |2              |\n",
      "|306    |3         |1230         |1317.0            |3951         |3              |\n",
      "|306    |4         |3345         |1858.0            |5574         |3              |\n",
      "|306    |5         |926          |1833.6666666666667|5501         |3              |\n",
      "|306    |6         |1970         |2080.3333333333335|6241         |3              |\n",
      "+-------+----------+-------------+------------------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Скользящие агрегаты (скользящее окно):\")\n",
    "\n",
    "df_sliding_agg = df.withColumn(\"rolling_avg_3\", \n",
    "                               avg(\"review_length\").over(window_sliding)) \\\n",
    "                   .withColumn(\"rolling_sum_3\", \n",
    "                               sum(\"review_length\").over(window_sliding)) \\\n",
    "                   .withColumn(\"rolling_count_3\", \n",
    "                               count(\"*\").over(window_sliding))\n",
    "\n",
    "print(\"   Скользящее среднее по 3 последним отзывам в фильме:\")\n",
    "\n",
    "print(\"\\n   Пример для фильма ID=306:\")\n",
    "sliding_example = df_sliding_agg.filter(col(\"film_id\") == 306) \\\n",
    "                               .select(\"film_id\", \"review_num\", \"review_length\",\n",
    "                                       \"rolling_avg_3\", \"rolling_sum_3\", \"rolling_count_3\") \\\n",
    "                               .orderBy(\"review_num\") \\\n",
    "                               .limit(6)\n",
    "sliding_example.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2af85c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Накопительные агрегаты (накопительное окно):\n",
      "   Накопительная статистика по фильмам:\n",
      "\n",
      "   Пример для фильма ID=306:\n",
      "+-------+----------+---------+-------------+-----------------+----------------+-----------+--------------------+\n",
      "|film_id|review_num|sentiment|review_length|cumulative_length|cumulative_count|running_avg|cumulative_positives|\n",
      "+-------+----------+---------+-------------+-----------------+----------------+-----------+--------------------+\n",
      "|306    |1         |pos      |1722         |1722             |1               |1722.0     |1                   |\n",
      "|306    |2         |pos      |999          |2721             |2               |1360.5     |2                   |\n",
      "|306    |3         |pos      |1230         |3951             |3               |1317.0     |3                   |\n",
      "|306    |4         |neu      |3345         |7296             |4               |1824.0     |3                   |\n",
      "|306    |5         |pos      |926          |8222             |5               |1644.4     |4                   |\n",
      "+-------+----------+---------+-------------+-----------------+----------------+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n5. Накопительные агрегаты (накопительное окно):\")\n",
    "\n",
    "df_cumulative = df.withColumn(\"cumulative_length\", \n",
    "                              sum(\"review_length\").over(window_cumulative)) \\\n",
    "                  .withColumn(\"cumulative_count\", \n",
    "                              count(\"*\").over(window_cumulative)) \\\n",
    "                  .withColumn(\"running_avg\", \n",
    "                              avg(\"review_length\").over(window_cumulative)) \\\n",
    "                  .withColumn(\"cumulative_positives\",\n",
    "                              sum(when(col(\"sentiment\") == \"pos\", 1).otherwise(0))\n",
    "                              .over(window_cumulative))\n",
    "\n",
    "print(\"   Накопительная статистика по фильмам:\")\n",
    "\n",
    "# Пример для конкретного фильма\n",
    "print(\"\\n   Пример для фильма ID=306:\")\n",
    "cumulative_example = df_cumulative.filter(col(\"film_id\") == 306) \\\n",
    "                                 .select(\"film_id\", \"review_num\", \"sentiment\",\n",
    "                                         \"review_length\", \"cumulative_length\",\n",
    "                                         \"cumulative_count\", \"running_avg\",\n",
    "                                         \"cumulative_positives\") \\\n",
    "                                 .orderBy(\"review_num\") \\\n",
    "                                 .limit(5)\n",
    "cumulative_example.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd19e9",
   "metadata": {},
   "source": [
    "Функции first_value() и last_value():  \n",
    "   • first_value() - значение из первой строки окна  \n",
    "   • last_value() - значение из последней строки окна  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa438db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Функции first_value() и last_value():\n",
      "\n",
      "   Пример сравнения с первым и последним отзывом:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 217:=====================================>               (86 + 12) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+--------------------+-------------------+---------------+--------------+\n",
      "|film_id|review_num|review_length|first_review_in_film|last_review_in_film|diff_from_first|diff_from_last|\n",
      "+-------+----------+-------------+--------------------+-------------------+---------------+--------------+\n",
      "|306    |1         |1722         |1722                |169                |0              |1553          |\n",
      "|306    |2         |999          |1722                |169                |-723           |830           |\n",
      "|306    |3         |1230         |1722                |169                |-492           |1061          |\n",
      "|306    |4         |3345         |1722                |169                |1623           |3176          |\n",
      "+-------+----------+-------------+--------------------+-------------------+---------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n6. Функции first_value() и last_value():\")\n",
    "\n",
    "df_first_last = df.withColumn(\"first_review_in_film\", \n",
    "                              first(\"review_length\").over(window_film_seq)) \\\n",
    "                  .withColumn(\"last_review_in_film\", \n",
    "                              last(\"review_length\").over(\n",
    "                                  Window.partitionBy(\"film_id\")\n",
    "                                        .orderBy(\"review_num\")\n",
    "                                        .rowsBetween(Window.unboundedPreceding, \n",
    "                                                   Window.unboundedFollowing)\n",
    "                              ))\n",
    "\n",
    "\n",
    "print(\"\\n   Пример сравнения с первым и последним отзывом:\")\n",
    "sample_comparison = df_first_last.filter(col(\"film_id\") == 306) \\\n",
    "                                .select(\"film_id\", \"review_num\", \"review_length\",\n",
    "                                        \"first_review_in_film\", \"last_review_in_film\",\n",
    "                                        (col(\"review_length\") - col(\"first_review_in_film\")).alias(\"diff_from_first\"),\n",
    "                                        (col(\"review_length\") - col(\"last_review_in_film\")).alias(\"diff_from_last\")) \\\n",
    "                                .orderBy(\"review_num\") \\\n",
    "                                .limit(4)\n",
    "sample_comparison.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845573",
   "metadata": {},
   "source": [
    "### Анализ \"спорных\" фильмов\n",
    "\n",
    "Задача: Найти фильмы с наиболее равномерным распределением тональностей  \n",
    "Определение: высокая 'спорность' = близкое количество neg/pos/neu отзывов  \n",
    "Метрика: низкое стандартное отклонение в распределении тональностей  \n",
    "\n",
    "Вычисляем метрики 'спорности':  \n",
    "   Формулы расчета:  \n",
    "   • total_reviews = neg + pos + neu  \n",
    "   • avg_count = total_reviews / 3   \n",
    "   • variance = Σ(count - avg_count)² / 3  \n",
    "   • std_dev = √variance (чем меньше, тем равномернее)  \n",
    "   • controversy_score = 1 / (std_dev + 1) (чем ближе к 1, тем спорнее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41509c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Создаем сводку распределения тональностей по фильмам:\n",
      "   Распределение по тональностям для первых 5 фильмов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+\n",
      "|film_id|neg|pos|neu|\n",
      "+-------+---+---+---+\n",
      "|306    |5  |31 |7  |\n",
      "|325    |2  |78 |8  |\n",
      "|331    |8  |60 |9  |\n",
      "|335    |12 |77 |6  |\n",
      "|342    |9  |74 |4  |\n",
      "+-------+---+---+---+\n",
      "\n",
      "\n",
      "2. Вычисляем метрики 'спорности':\n",
      "3. ТОП-10 САМЫХ 'СПОРНЫХ' ФИЛЬМОВ\n",
      "   (близкое распределение тональностей)\n",
      "Фильмы с наиболее равномерным распределением тональностей:\n",
      "(минимум 10 отзывов)\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Film ID  Neg  Pos  Neu  Total  Neg%  Pos%  Neu%  StdDev   Score \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102221   5    5    5    15     33    33    33    0.00     1.000 \n",
      "293837   4    4    4    12     33    33    33    0.00     1.000 \n",
      "418113   5    5    5    15     33    33    33    0.00     1.000 \n",
      "22635    4    4    4    12     33    33    33    0.00     1.000 \n",
      "8065     6    6    6    18     33    33    33    0.00     1.000 \n",
      "453615   7    6    7    20     35    30    35    0.47     0.680 \n",
      "618381   3    3    4    10     30    30    40    0.47     0.680 \n",
      "893627   4    4    3    11     36    36    27    0.47     0.680 \n",
      "427272   4    5    5    14     28    35    35    0.47     0.680 \n",
      "1128272  7    6    7    20     35    30    35    0.47     0.680 \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "4. ТОП-10 САМЫХ 'ОДНОЗНАЧНЫХ' ФИЛЬМОВ\n",
      "   (преобладание одной тональности)\n",
      "Фильмы с преобладанием одной тональности:\n",
      "Film ID  Neg  Pos  Neu  Total  Dominant  Dominance%  StdDev   Score \n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950     1    98   0    99     pos       98          45.96    0.021 \n",
      "42664    0    90   2    92     pos       97          41.96    0.023 \n",
      "5330     1    90   3    94     pos       95          41.49    0.024 \n",
      "414      1    88   3    92     pos       95          40.55    0.024 \n",
      "77164    2    88   2    92     pos       95          40.54    0.024 \n",
      "1991     2    88   5    95     pos       92          39.85    0.024 \n",
      "89514    0    86   4    90     pos       95          39.63    0.025 \n",
      "7097     2    88   6    96     pos       91          39.63    0.025 \n",
      "259829   5    88   4    97     pos       90          39.36    0.025 \n",
      "555      3    87   5    95     pos       91          39.14    0.025 \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "5. ОБЩАЯ СТАТИСТИКА ПО ВСЕМ ФИЛЬМАМ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего фильмов (с ≥5 отзывами): 3,776\n",
      "Средний показатель спорности: 0.238\n",
      "Разброс показателей спорности: 0.160\n",
      "Минимальная спорность: 0.021\n",
      "Максимальная спорность: 1.000\n",
      "Среднее количество отзывов на фильм: 26.5\n",
      "\n",
      "Распределение фильмов по уровню спорности:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.0-0.2 | ███████████████████████ 1788 фильмов (47.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2-0.4 | ███████████████████ 1447 фильмов (38.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.4-0.6 | █████  427 фильмов (11.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.6-0.8 | █   99 фильмов (2.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.8-1   |     0 фильмов (0.0%)\n",
      "6. ПРИМЕРЫ ОТЗЫВОВ ДЛЯ САМЫХ СПОРНЫХ ФИЛЬМОВ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Фильм ID=418113:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Распределение: Neg=5, Pos=5, Neu=5\n",
      "  Всего отзывов: 15\n",
      "  Показатель спорности: 1.000\n",
      "  Примеры отзывов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    POS: Отзыв 5 - Фильм Марка А. Льюиса действительно по новому, вернул интерес к ужастикам про па...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEG: Отзыв 1 - Как многие помнят, был такой, достаточно удачный и интересный сериал, под назван...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEU: Отзыв 2 - “Оттепель” – это первый полнометражный дебютный проект режиссера – сценариста Ма...\n",
      "\n",
      "Фильм ID=8065:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Распределение: Neg=6, Pos=6, Neu=6\n",
      "  Всего отзывов: 18\n",
      "  Показатель спорности: 1.000\n",
      "  Примеры отзывов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    POS: Отзыв 1 - Объясните мне, как взрослый человек может категорично утверждать, что детям не п...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEG: Отзыв 5 - Фильм «Кот» … Я даже не знаю, что можно о нем сказать. Ужасно глупый и  бессмысл...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEU: Отзыв 7 - Ну... не знаю. Весь фильм ты сидишь спокойно, а на экране каждую секунду что-то ...\n",
      "\n",
      "Фильм ID=22635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Распределение: Neg=4, Pos=4, Neu=4\n",
      "  Всего отзывов: 12\n",
      "  Показатель спорности: 1.000\n",
      "  Примеры отзывов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    POS: Отзыв 7 - Вторая часть получилась куда хуже в плане атмосферности и игры актёров, лучше вс...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEG: Отзыв 1 - Вторая часть 'У холмов есть глаза' выходит в пик популярности Джейсона Вурхиза и...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NEU: Отзыв 5 - Режиссёр Уэс Крейвен?! Да, действительно, он. Конечно, у каждого бывают не очень...\n",
      "Сохранение таблицы с метриками спорности фильмов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Сохранено: data/processed/film_controversy_analysis.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Количество фильмов: 9,065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 343:============================================>       (106 + 13) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Сохранено: data/processed/top_100_controversial_films.parquet\n",
      "✓ Сохранено топ-100 самых спорных фильмов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sqrt, pow\n",
    "\n",
    "\n",
    "print(\"\\n1. Создаем сводку распределения тональностей по фильмам:\")\n",
    "sentiment_distribution = df.groupBy(\"film_id\", \"sentiment\") \\\n",
    "    .agg(count(\"*\").alias(\"count_by_sentiment\")) \\\n",
    "    .groupBy(\"film_id\") \\\n",
    "    .pivot(\"sentiment\", [\"neg\", \"pos\", \"neu\"]) \\\n",
    "    .agg(first(\"count_by_sentiment\")) \\\n",
    "    .fillna(0)  \n",
    "\n",
    "print(\"   Распределение по тональностям для первых 5 фильмов:\")\n",
    "sentiment_distribution.orderBy(\"film_id\").limit(5).show(truncate=False)\n",
    "\n",
    "print(\"\\n2. Вычисляем метрики 'спорности':\")\n",
    "controversial_films = sentiment_distribution \\\n",
    "    .withColumn(\"total_reviews\", col(\"neg\") + col(\"pos\") + col(\"neu\")) \\\n",
    "    .withColumn(\"avg_count\", col(\"total_reviews\") / 3) \\\n",
    "    .withColumn(\"variance\", \n",
    "               (pow(col(\"neg\") - col(\"avg_count\"), 2) + \n",
    "                pow(col(\"pos\") - col(\"avg_count\"), 2) + \n",
    "                pow(col(\"neu\") - col(\"avg_count\"), 2)) / 3) \\\n",
    "    .withColumn(\"std_dev\", sqrt(col(\"variance\"))) \\\n",
    "    .withColumn(\"controversy_score\", 1 / (col(\"std_dev\") + 1))  # +1 чтобы избежать деления на 0\n",
    "\n",
    "print(\"3. ТОП-10 САМЫХ 'СПОРНЫХ' ФИЛЬМОВ\")\n",
    "print(\"   (близкое распределение тональностей)\")\n",
    "\n",
    "top_controversial = controversial_films \\\n",
    "    .filter(col(\"total_reviews\") >= 10) \\\n",
    "    .select(\"film_id\", \"neg\", \"pos\", \"neu\", \"total_reviews\", \n",
    "           \"std_dev\", \"controversy_score\") \\\n",
    "    .withColumn(\"neg_percent\", (col(\"neg\") / col(\"total_reviews\") * 100).cast(\"int\")) \\\n",
    "    .withColumn(\"pos_percent\", (col(\"pos\") / col(\"total_reviews\") * 100).cast(\"int\")) \\\n",
    "    .withColumn(\"neu_percent\", (col(\"neu\") / col(\"total_reviews\") * 100).cast(\"int\")) \\\n",
    "    .orderBy(col(\"controversy_score\").desc()) \\\n",
    "    .limit(10)\n",
    "\n",
    "print(\"Фильмы с наиболее равномерным распределением тональностей:\")\n",
    "print(\"(минимум 10 отзывов)\")\n",
    "print(\"\\n\" + \"-\"*120)\n",
    "print(f\"{'Film ID':<8} {'Neg':<4} {'Pos':<4} {'Neu':<4} {'Total':<6} {'Neg%':<5} {'Pos%':<5} {'Neu%':<5} {'StdDev':<8} {'Score':<6}\")\n",
    "print(\"-\"*120)\n",
    "\n",
    "for row in top_controversial.collect():\n",
    "    print(f\"{row['film_id']:<8} {row['neg']:<4} {row['pos']:<4} {row['neu']:<4} \"\n",
    "          f\"{row['total_reviews']:<6} {row['neg_percent']:<5} {row['pos_percent']:<5} \"\n",
    "          f\"{row['neu_percent']:<5} {row['std_dev']:<8.2f} {row['controversy_score']:<6.3f}\")\n",
    "\n",
    "print(\"-\"*120)\n",
    "\n",
    "print(\"4. ТОП-10 САМЫХ 'ОДНОЗНАЧНЫХ' ФИЛЬМОВ\")\n",
    "print(\"   (преобладание одной тональности)\")\n",
    "\n",
    "top_unambiguous = controversial_films \\\n",
    "    .filter(col(\"total_reviews\") >= 10) \\\n",
    "    .select(\"film_id\", \"neg\", \"pos\", \"neu\", \"total_reviews\", \n",
    "           \"std_dev\", \"controversy_score\") \\\n",
    "    .withColumn(\"max_sentiment\", \n",
    "               when(col(\"neg\") >= col(\"pos\"), \n",
    "                    when(col(\"neg\") >= col(\"neu\"), \"neg\").otherwise(\"neu\"))\n",
    "               .otherwise(when(col(\"pos\") >= col(\"neu\"), \"pos\").otherwise(\"neu\"))) \\\n",
    "    .withColumn(\"max_count\", \n",
    "               greatest(col(\"neg\"), col(\"pos\"), col(\"neu\"))) \\\n",
    "    .withColumn(\"dominance_percent\", (col(\"max_count\") / col(\"total_reviews\") * 100).cast(\"int\")) \\\n",
    "    .orderBy(\"controversy_score\") \\\n",
    "    .limit(10)\n",
    "\n",
    "print(\"Фильмы с преобладанием одной тональности:\")\n",
    "print(f\"{'Film ID':<8} {'Neg':<4} {'Pos':<4} {'Neu':<4} {'Total':<6} {'Dominant':<9} {'Dominance%':<11} {'StdDev':<8} {'Score':<6}\")\n",
    "print(\"-\"*120)\n",
    "\n",
    "for row in top_unambiguous.collect():\n",
    "    print(f\"{row['film_id']:<8} {row['neg']:<4} {row['pos']:<4} {row['neu']:<4} \"\n",
    "          f\"{row['total_reviews']:<6} {row['max_sentiment']:<9} \"\n",
    "          f\"{row['dominance_percent']:<11} {row['std_dev']:<8.2f} {row['controversy_score']:<6.3f}\")\n",
    "\n",
    "print(\"-\"*120)\n",
    "\n",
    "print(\"5. ОБЩАЯ СТАТИСТИКА ПО ВСЕМ ФИЛЬМАМ\")\n",
    "\n",
    "# Рассчитываем статистику по распределению спорности\n",
    "controversy_stats = controversial_films \\\n",
    "    .filter(col(\"total_reviews\") >= 5) \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_films\"),\n",
    "        avg(\"controversy_score\").alias(\"avg_controversy_score\"),\n",
    "        stddev(\"controversy_score\").alias(\"std_controversy_score\"),\n",
    "        min(\"controversy_score\").alias(\"min_controversy_score\"),\n",
    "        max(\"controversy_score\").alias(\"max_controversy_score\"),\n",
    "        avg(\"total_reviews\").alias(\"avg_reviews_per_film\")\n",
    "    ).collect()[0]\n",
    "\n",
    "print(f\"Всего фильмов (с ≥5 отзывами): {controversy_stats['total_films']:,}\")\n",
    "print(f\"Средний показатель спорности: {controversy_stats['avg_controversy_score']:.3f}\")\n",
    "print(f\"Разброс показателей спорности: {controversy_stats['std_controversy_score']:.3f}\")\n",
    "print(f\"Минимальная спорность: {controversy_stats['min_controversy_score']:.3f}\")\n",
    "print(f\"Максимальная спорность: {controversy_stats['max_controversy_score']:.3f}\")\n",
    "print(f\"Среднее количество отзывов на фильм: {controversy_stats['avg_reviews_per_film']:.1f}\")\n",
    "\n",
    "print(\"\\nРаспределение фильмов по уровню спорности:\")\n",
    "controversy_bins = [(0.0, 0.2), (0.2, 0.4), (0.4, 0.6), (0.6, 0.8), (0.8, 1.0)]\n",
    "\n",
    "for low, high in controversy_bins:\n",
    "    count = controversial_films \\\n",
    "        .filter((col(\"controversy_score\") >= low) & (col(\"controversy_score\") < high) & \n",
    "                (col(\"total_reviews\") >= 5)) \\\n",
    "        .count()\n",
    "    percentage = count / controversy_stats['total_films'] * 100\n",
    "    bar_length = int(percentage / 2)  # масштабируем для отображения\n",
    "    bar = \"█\" * bar_length\n",
    "    \n",
    "    label = f\"{low:.1f}-{high:.1f}\"\n",
    "    if high == 1.0:\n",
    "        label = f\"{low:.1f}-{high:.0f}\"\n",
    "    \n",
    "    print(f\"  {label:7} | {bar} {count:4d} фильмов ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"6. ПРИМЕРЫ ОТЗЫВОВ ДЛЯ САМЫХ СПОРНЫХ ФИЛЬМОВ\")\n",
    "\n",
    "# ID самых спорных фильмов\n",
    "top_controversial_ids = [row[\"film_id\"] for row in top_controversial.limit(3).collect()]\n",
    "\n",
    "for film_id in top_controversial_ids:\n",
    "    print(f\"\\nФильм ID={film_id}:\")\n",
    "    \n",
    "    # получаем распределение по тональностям\n",
    "    film_stats = controversial_films.filter(col(\"film_id\") == film_id).first()\n",
    "    \n",
    "    print(f\"  Распределение: Neg={film_stats['neg']}, Pos={film_stats['pos']}, Neu={film_stats['neu']}\")\n",
    "    print(f\"  Всего отзывов: {film_stats['total_reviews']}\")\n",
    "    print(f\"  Показатель спорности: {film_stats['controversy_score']:.3f}\")\n",
    "    \n",
    "    print(\"  Примеры отзывов:\")\n",
    "    \n",
    "    for sentiment in [\"pos\", \"neg\", \"neu\"]:\n",
    "        sample_review = df.filter((col(\"film_id\") == film_id) & (col(\"sentiment\") == sentiment)) \\\n",
    "                         .select(\"review_num\", \"sentiment\", \n",
    "                                 substring(\"review_text\", 1, 80).alias(\"text_preview\")) \\\n",
    "                         .orderBy(\"review_num\") \\\n",
    "                         .limit(1) \\\n",
    "                         .first()\n",
    "        \n",
    "        if sample_review:\n",
    "            print(f\"    {sentiment.upper()}: Отзыв {sample_review['review_num']} - {sample_review['text_preview']}...\")\n",
    "\n",
    "print(\"Сохранение таблицы с метриками спорности фильмов...\")\n",
    "\n",
    "controversial_films.select(\n",
    "    \"film_id\", \"neg\", \"pos\", \"neu\", \"total_reviews\",\n",
    "    \"avg_count\", \"variance\", \"std_dev\", \"controversy_score\"\n",
    ").write.mode(\"overwrite\").parquet(\"data/processed/film_controversy_analysis.parquet\")\n",
    "\n",
    "print(f\"✓ Сохранено: data/processed/film_controversy_analysis.parquet\")\n",
    "print(f\"✓ Количество фильмов: {controversial_films.count():,}\")\n",
    "\n",
    "# сохраняем топ-100 самых спорных фильмов для быстрого доступа\n",
    "top_100_controversial = controversial_films \\\n",
    "    .filter(col(\"total_reviews\") >= 10) \\\n",
    "    .orderBy(col(\"controversy_score\").desc()) \\\n",
    "    .limit(100)\n",
    "\n",
    "top_100_controversial.write.mode(\"overwrite\").parquet(\"data/processed/top_100_controversial_films.parquet\")\n",
    "print(f\"✓ Сохранено: data/processed/top_100_controversial_films.parquet\")\n",
    "print(f\"✓ Сохранено топ-100 самых спорных фильмов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d576c",
   "metadata": {},
   "source": [
    "### Часть 3. Векторизация текста: от слов к числам\n",
    "\n",
    "Текст должен быть преобразован в числовые векторы, так как алгоритмы машинного обучения работают только с числами.\n",
    "\n",
    "1. TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Это классический и эффективный метод, который оценивает важность слова в документе относительно всей коллекции документов.\n",
    "\n",
    "| Компонент | Описание | Логика |\n",
    "| :--- | :--- | :--- |\n",
    "| Term Frequency (TF) | Как часто слово встречается в данном документе. | Частое слово в отзыве = потенциально важное для него. |\n",
    "| Inverse Document Frequency (IDF) | Насколько редко слово встречается во всей коллекции документов. | Редкое слово в целом = более уникальное и информативное. |\n",
    "| TF-IDF | Произведение TF и IDF. | Высокий вес получают слова, которые часты в конкретном документе, но редки в других. |\n",
    "\n",
    "Реализация в PySpark: TF часто вычисляется с помощью `HashingTF`, который быстро сопоставляет слова с индексами фичей, а затем применяется `IDF`.\n",
    "\n",
    "2. Word2Vec (семантические эмбеддинги)\n",
    "Это более продвинутый подход, который создает \"плотные\" векторные представления слов, учитывая их смысловой контекст.\n",
    "*   Принцип: Слова, встречающиеся в похожих контекстах (например, \"отличный\" и \"прекрасный\"), получают близкие по значению векторы.\n",
    "*   Архитектуры:\n",
    "    *   CBOW: Предсказывает слово по его контексту.\n",
    "    *   Skip-gram: Предсказывает контекст по заданному слову (чаще используется).\n",
    "*   Результат: На выходе получается модель, которая может находить семантически близкие слова (синонимы) с помощью `findSynonyms()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdc58b",
   "metadata": {},
   "source": [
    "#### Базовая токенизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69746b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Токенизировано отзывов: 109,998\n",
      "\n",
      "   Примеры токенизации (первые 3 отзыва):\n",
      "\n",
      "   Пример 1 (Фильм 841263, отзыв 86):\n",
      "   Тональность: pos\n",
      "   Текст: С момента появления первых фильмов от 'Марвел' прошло уже прилично вре...\n",
      "   Токены: ['с', 'момента', 'появления', 'первых', 'фильмов', 'от', \"'марвел'\", 'прошло', 'уже', 'прилично']\n",
      "   Всего слов: 776\n",
      "\n",
      "   Пример 2 (Фильм 906042, отзыв 34):\n",
      "   Тональность: pos\n",
      "   Текст: Паддингтон - лучший медведь в кино? Этот вопрос меня уже долго мучает,...\n",
      "   Токены: ['паддингтон', '-', 'лучший', 'медведь', 'в', 'кино?', 'этот', 'вопрос', 'меня', 'уже']\n",
      "   Всего слов: 798\n",
      "\n",
      "   Пример 3 (Фильм 230752, отзыв 2):\n",
      "   Тональность: neg\n",
      "   Текст: Абсурд.\n",
      "\n",
      "Представьте себе Илью Муромца, вот он в первой серии едет в К...\n",
      "   Токены: ['абсурд.', '', 'представьте', 'себе', 'илью', 'муромца,', 'вот', 'он', 'в', 'первой']\n",
      "   Всего слов: 769\n",
      "\n",
      "   Статистика по токенам (до очистки):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------------------+-------------+-------------+\n",
      "|sentiment|    avg_words_raw|     std_words_raw|min_words_raw|max_words_raw|\n",
      "+---------+-----------------+------------------+-------------+-------------+\n",
      "|      neg|323.0762412409415| 159.1177517092739|           11|          953|\n",
      "|      pos| 313.285667310617|158.95934092206323|            8|         1130|\n",
      "|      neu|307.6399035148174| 161.0270660152362|            9|          856|\n",
      "+---------+-----------------+------------------+-------------+-------------+\n",
      "\n",
      "\n",
      "   Анализ длины отзывов по фильмам:\n",
      "   Топ-5 фильмов с самыми длинными отзывами:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+\n",
      "|film_id|avg_words_per_review|total_reviews|\n",
      "+-------+--------------------+-------------+\n",
      "| 225362|               801.0|            1|\n",
      "|1108925|               792.0|            1|\n",
      "|  64538|               786.0|            1|\n",
      "| 218483|               786.0|            1|\n",
      "|   3653|               784.0|            1|\n",
      "+-------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, RegexTokenizer\n",
    "from pyspark.sql.functions import size, array_contains\n",
    "from pyspark.sql.functions import col, size, avg, count as sql_count\n",
    "\n",
    "# Способ 1: базовый Tokenizer (разделяет по пробелам)\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"words_raw\")\n",
    "df_tokenized = tokenizer.transform(df)\n",
    "\n",
    "print(f\"   Токенизировано отзывов: {df_tokenized.count():,}\")\n",
    "\n",
    "print(\"\\n   Примеры токенизации (первые 3 отзыва):\")\n",
    "samples = df_tokenized.select(\"film_id\", \"review_num\", \"sentiment\", \n",
    "                              \"review_text\", \"words_raw\").limit(3).collect()\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    original_preview = sample[\"review_text\"][:70] + \"...\" if len(sample[\"review_text\"]) > 70 else sample[\"review_text\"]\n",
    "    words_preview = sample[\"words_raw\"][:10]  # показываем первые 10 слов\n",
    "    \n",
    "    print(f\"\\n   Пример {i+1} (Фильм {sample['film_id']}, отзыв {sample['review_num']}):\")\n",
    "    print(f\"   Тональность: {sample['sentiment']}\")\n",
    "    print(f\"   Текст: {original_preview}\")\n",
    "    print(f\"   Токены: {words_preview}\")\n",
    "    print(f\"   Всего слов: {len(sample['words_raw'])}\")\n",
    "\n",
    "# статистика по токенам до очистки\n",
    "print(\"\\n   Статистика по токенам (до очистки):\")\n",
    "token_stats_raw = df_tokenized.withColumn(\"word_count_raw\", size(col(\"words_raw\"))) \\\n",
    "                             .groupBy(\"sentiment\") \\\n",
    "                             .agg(\n",
    "                                 avg(\"word_count_raw\").alias(\"avg_words_raw\"),\n",
    "                                 stddev(\"word_count_raw\").alias(\"std_words_raw\"),\n",
    "                                 min(\"word_count_raw\").alias(\"min_words_raw\"),\n",
    "                                 max(\"word_count_raw\").alias(\"max_words_raw\")\n",
    "                             ).orderBy(\"avg_words_raw\", ascending=False)\n",
    "\n",
    "token_stats_raw.show()\n",
    "\n",
    "# анализ длины отзывов по фильмам\n",
    "print(\"\\n   Анализ длины отзывов по фильмам:\")\n",
    "film_word_stats = df_tokenized.groupBy(\"film_id\") \\\n",
    "                             .agg(\n",
    "                                 avg(size(col(\"words_raw\"))).alias(\"avg_words_per_review\"),\n",
    "                                 sql_count(\"*\").alias(\"total_reviews\")\n",
    "                             ).orderBy(col(\"avg_words_per_review\").desc())\n",
    "\n",
    "print(\"   Топ-5 фильмов с самыми длинными отзывами:\")\n",
    "film_word_stats.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f951b0",
   "metadata": {},
   "source": [
    "#### Расширенная токенизация с очисткой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e61b50a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   а) Предварительная очистка текста:\n",
      "   б) Улучшенная токенизация для русского языка:\n",
      "\n",
      "   в) Сравнение до и после очистки:\n",
      "\n",
      "   Пример 1 (Фильм 841263):\n",
      "   Оригинал: С момента появления первых фильмов от 'Марвел' про\n",
      "   Очищенный: момента появления первых фильмов от   арвел  прошл\n",
      "   Токены (сырые): ['с', 'момента', 'появления', 'первых', 'фильмов', 'от', \"'марвел'\", 'прошло']\n",
      "   Токены (очищенные): ['момента', 'появления', 'первых', 'фильмов', 'от', 'арвел', 'прошло', 'уже']\n",
      "   Удалено символов/токенов: 32\n",
      "\n",
      "   Пример 2 (Фильм 906042):\n",
      "   Оригинал: Паддингтон - лучший медведь в кино? Этот вопрос ме\n",
      "   Очищенный: аддингтон   лучший медведь в кино   тот вопрос мен\n",
      "   Токены (сырые): ['паддингтон', '-', 'лучший', 'медведь', 'в', 'кино?', 'этот', 'вопрос']\n",
      "   Токены (очищенные): ['аддингтон', 'лучший', 'медведь', 'в', 'кино', 'тот', 'вопрос', 'меня']\n",
      "   Удалено символов/токенов: 31\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, regexp_replace, trim\n",
    "\n",
    "# предварительная очистка текста\n",
    "print(\"   а) Предварительная очистка текста:\")\n",
    "df_cleaned = df_tokenized.withColumn(\n",
    "    \"cleaned_text\",\n",
    "    trim(lower(regexp_replace(col(\"review_text\"), \"[^а-яёa-z0-9\\\\s]\", \" \")))\n",
    ")\n",
    "\n",
    "# улучшенная токенизация с учетом русского языка\n",
    "print(\"   б) Улучшенная токенизация для русского языка:\")\n",
    "regex_tokenizer = RegexTokenizer(\n",
    "    inputCol=\"cleaned_text\",\n",
    "    outputCol=\"words_clean\",\n",
    "    pattern=\"\\\\s+\",  # разделитель - один или более пробельных символов\n",
    "    gaps=True\n",
    ")\n",
    "\n",
    "df_tokenized_clean = regex_tokenizer.transform(df_cleaned)\n",
    "\n",
    "# удаляем пустые токены\n",
    "df_tokenized_clean = df_tokenized_clean.withColumn(\n",
    "    \"words_filtered\",\n",
    "    array_remove(col(\"words_clean\"), \"\")\n",
    ")\n",
    "\n",
    "# сравнение до и после очистки\n",
    "print(\"\\n   в) Сравнение до и после очистки:\")\n",
    "comparison_sample = df_tokenized_clean.select(\n",
    "    \"film_id\", \"review_num\",\n",
    "    substring(\"review_text\", 1, 50).alias(\"original_preview\"),\n",
    "    substring(\"cleaned_text\", 1, 50).alias(\"cleaned_preview\"),\n",
    "    col(\"words_raw\").alias(\"tokens_raw\"),\n",
    "    col(\"words_filtered\").alias(\"tokens_clean\")\n",
    ").limit(2).collect()\n",
    "\n",
    "for i, sample in enumerate(comparison_sample):\n",
    "    print(f\"\\n   Пример {i+1} (Фильм {sample['film_id']}):\")\n",
    "    print(f\"   Оригинал: {sample['original_preview']}\")\n",
    "    print(f\"   Очищенный: {sample['cleaned_preview']}\")\n",
    "    print(f\"   Токены (сырые): {sample['tokens_raw'][:8]}\")\n",
    "    print(f\"   Токены (очищенные): {sample['tokens_clean'][:8]}\")\n",
    "    \n",
    "    diff = len(sample['tokens_raw']) - len(sample['tokens_clean'])\n",
    "    if diff > 0:\n",
    "        print(f\"   Удалено символов/токенов: {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf5826",
   "metadata": {},
   "source": [
    "#### Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f7731ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Всего стоп-слов: 169\n",
      "   Из них общих: 151\n",
      "   Контекстных (фильмы): 18\n",
      "\n",
      "   Примеры стоп-слов:\n",
      "   Общие: ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']\n",
      "   Контекстные: ['фильм', 'кино', 'смотреть', 'режиссер', 'актер', 'актриса', 'роль', 'сюжет', 'концовка', 'кадр', 'эпизод', 'сцена', 'персонаж', 'герой', 'картина', 'лента', 'просмотр', 'кинолента']\n",
      "\n",
      "  Эффективность удаления стоп-слов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+---------------------+-------------------+\n",
      "|sentiment|  avg_words_before|   avg_words_after|avg_stopwords_removed|avg_removal_percent|\n",
      "+---------+------------------+------------------+---------------------+-------------------+\n",
      "|      neg| 310.2595675869917|200.40648020602504|   109.85308738096664|  35.41035172509948|\n",
      "|      neu|295.89243871221817|193.00310130944177|    102.8893374027764|  34.85853558458868|\n",
      "|      pos|299.73392521955964|197.65829531286394|   102.07562990669571|  34.06615881585567|\n",
      "+---------+------------------+------------------+---------------------+-------------------+\n",
      "\n",
      "\n",
      "   Пример удаления стоп-слов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-----------+--------------+------------+------------------+------------------------------------------------------------+\n",
      "|film_id|review_num|sentiment|до_удаления|после_удаления|удалено_слов|процент_удаления  |текст                                                       |\n",
      "+-------+----------+---------+-----------+--------------+------------+------------------+------------------------------------------------------------+\n",
      "|463149 |30        |neg      |795        |433           |362         |45.534591194968556|В центре сюжета любовный треугольник: Декс любит Рейчел, Рей|\n",
      "|42664  |7         |neu      |751        |394           |357         |47.53661784287617 |Что же посмотреть перед Новым годом, если не всеми любимую к|\n",
      "|710276 |40        |neg      |764        |408           |356         |46.596858638743456|Так много сказано, так мало сделано. Наверное, я выросла из |\n",
      "+-------+----------+---------+-----------+--------------+------------+------------------+------------------------------------------------------------+\n",
      "\n",
      "\n",
      "   Сохранение подготовленных данных...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 378:=============================================>      (108 + 12) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Данные сохранены: data/processed/reviews_tokenized.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "russian_stopwords = [\n",
    "    \"и\", \"в\", \"во\", \"не\", \"что\", \"он\", \"на\", \"я\", \"с\", \"со\", \"как\", \"а\", \"то\", \"все\",\n",
    "    \"она\", \"так\", \"его\", \"но\", \"да\", \"ты\", \"к\", \"у\", \"же\", \"вы\", \"за\", \"бы\", \"по\",\n",
    "    \"только\", \"ее\", \"мне\", \"было\", \"вот\", \"от\", \"меня\", \"еще\", \"нет\", \"о\", \"из\", \"ему\",\n",
    "    \"теперь\", \"когда\", \"даже\", \"ну\", \"вдруг\", \"ли\", \"если\", \"уже\", \"или\", \"ни\", \"быть\",\n",
    "    \"был\", \"него\", \"до\", \"вас\", \"нибудь\", \"опять\", \"уж\", \"вам\", \"ведь\", \"там\", \"потом\",\n",
    "    \"себя\", \"ничего\", \"ей\", \"может\", \"они\", \"тут\", \"где\", \"есть\", \"надо\", \"ней\", \"для\",\n",
    "    \"мы\", \"тебя\", \"их\", \"чем\", \"была\", \"сам\", \"чтоб\", \"без\", \"будто\", \"чего\", \"раз\",\n",
    "    \"тоже\", \"себе\", \"под\", \"будет\", \"ж\", \"тогда\", \"кто\", \"этот\", \"того\", \"потому\",\n",
    "    \"этого\", \"какой\", \"совсем\", \"ним\", \"здесь\", \"этом\", \"один\", \"почти\", \"мой\", \"тем\",\n",
    "    \"чтобы\", \"нее\", \"сейчас\", \"были\", \"куда\", \"зачем\", \"всех\", \"никогда\", \"можно\",\n",
    "    \"при\", \"наконец\", \"два\", \"об\", \"другой\", \"хоть\", \"после\", \"над\", \"больше\", \"тот\",\n",
    "    \"через\", \"эти\", \"нас\", \"про\", \"всего\", \"них\", \"какая\", \"много\", \"разве\", \"три\",\n",
    "    \"эту\", \"моя\", \"впрочем\", \"хорошо\", \"свою\", \"этой\", \"перед\", \"иногда\", \"лучше\",\n",
    "    \"чуть\", \"том\", \"нельзя\", \"такой\", \"им\", \"более\", \"всегда\", \"конечно\", \"всю\", \"между\"\n",
    "]\n",
    "\n",
    "film_stopwords = [\n",
    "    \"фильм\", \"кино\", \"смотреть\", \"режиссер\", \"актер\", \"актриса\", \"роль\",\n",
    "    \"сюжет\", \"концовка\", \"кадр\", \"эпизод\", \"сцена\", \"персонаж\", \"герой\",\n",
    "    \"картина\", \"лента\", \"просмотр\", \"кинолента\"\n",
    "]\n",
    "\n",
    "# объединяем стоп-слова\n",
    "custom_stopwords = russian_stopwords + film_stopwords\n",
    "print(f\"   Всего стоп-слов: {len(custom_stopwords)}\")\n",
    "print(f\"   Из них общих: {len(russian_stopwords)}\")\n",
    "print(f\"   Контекстных (фильмы): {len(film_stopwords)}\")\n",
    "\n",
    "print(\"\\n   Примеры стоп-слов:\")\n",
    "print(f\"   Общие: {russian_stopwords[:10]}\")\n",
    "print(f\"   Контекстные: {film_stopwords}\")\n",
    "\n",
    "# инициализируем удаление стоп-слов\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"words_filtered\",\n",
    "    outputCol=\"words_without_stopwords\",\n",
    "    stopWords=custom_stopwords\n",
    ")\n",
    "\n",
    "# применяем удаление стоп-слов\n",
    "df_no_stopwords = stopwords_remover.transform(df_tokenized_clean)\n",
    "\n",
    "# анализ эффективности удаления стоп-слов\n",
    "print(\"\\n  Эффективность удаления стоп-слов:\")\n",
    "\n",
    "stopword_analysis = df_no_stopwords.withColumn(\n",
    "    \"words_before\", size(col(\"words_filtered\"))\n",
    ").withColumn(\n",
    "    \"words_after\", size(col(\"words_without_stopwords\"))\n",
    ").withColumn(\n",
    "    \"stopwords_removed\", col(\"words_before\") - col(\"words_after\")\n",
    ").withColumn(\n",
    "    \"removal_percentage\", (col(\"stopwords_removed\") / col(\"words_before\")) * 100\n",
    ")\n",
    "\n",
    "# статистика по удалению\n",
    "removal_stats = stopword_analysis.groupBy(\"sentiment\").agg(\n",
    "    avg(\"words_before\").alias(\"avg_words_before\"),\n",
    "    avg(\"words_after\").alias(\"avg_words_after\"),\n",
    "    avg(\"stopwords_removed\").alias(\"avg_stopwords_removed\"),\n",
    "    avg(\"removal_percentage\").alias(\"avg_removal_percent\")\n",
    ").orderBy(\"avg_removal_percent\", ascending=False)\n",
    "\n",
    "removal_stats.show()\n",
    "\n",
    "print(\"\\n   Пример удаления стоп-слов:\")\n",
    "sample_removal = stopword_analysis.select(\n",
    "    \"film_id\", \"review_num\", \"sentiment\",\n",
    "    col(\"words_before\").alias(\"до_удаления\"),\n",
    "    col(\"words_after\").alias(\"после_удаления\"),\n",
    "    col(\"stopwords_removed\").alias(\"удалено_слов\"),\n",
    "    col(\"removal_percentage\").alias(\"процент_удаления\"),\n",
    "    substring(\"review_text\", 1, 60).alias(\"текст\")\n",
    ").orderBy(col(\"удалено_слов\").desc()).limit(3)\n",
    "\n",
    "sample_removal.show(truncate=False)\n",
    "\n",
    "# сохраняем промежуточные результаты\n",
    "print(\"\\n   Сохранение подготовленных данных...\")\n",
    "df_no_stopwords.write.mode(\"overwrite\").parquet(\"data/processed/reviews_tokenized.parquet\")\n",
    "print(\"    Данные сохранены: data/processed/reviews_tokenized.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055c60c",
   "metadata": {},
   "source": [
    "#### Дополнительная очистка и нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b01b9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   После фильтрации (минимум 3 слова): 109,998 из 109,998 отзывов\n",
      "   Удалено: 0 отзывов\n",
      "\n",
      "   Итоговая статистика по токенам:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+---------------+---------------+------------+\n",
      "|sentiment|   avg_final_words|   std_final_words|min_final_words|max_final_words|review_count|\n",
      "+---------+------------------+------------------+---------------+---------------+------------+\n",
      "|      neg|195.83787506737738| 99.34245729667747|              8|            525|       16697|\n",
      "|      pos| 193.5098168166934|101.26014404459588|              5|            571|       72987|\n",
      "|      neu|189.14157723737324|102.35256083840292|              6|            538|       20314|\n",
      "+---------+------------------+------------------+---------------+---------------+------------+\n",
      "\n",
      "\n",
      "   Сохранение финальных подготовленных данных...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 394:==============================================>     (109 + 12) / 123]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Данные сохранены: data/processed/reviews_prepared_for_ml.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import re\n",
    "\n",
    "# функция для дополнительной очистки токенов\n",
    "def clean_tokens(tokens):\n",
    "    \"\"\"Очистка токенов: удаление коротких слов, чисел, пунктуации\"\"\"\n",
    "    cleaned = []\n",
    "    for token in tokens:\n",
    "        # удаляем токены короче 2 символов\n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "        \n",
    "        # удаляем токены, состоящие только из цифр\n",
    "        if token.isdigit():\n",
    "            continue\n",
    "        \n",
    "        # удаляем токены с цифрами\n",
    "        if any(char.isdigit() for char in token):\n",
    "            continue\n",
    "        \n",
    "        # приводим к нижнему регистру (на всякий случай)\n",
    "        token = token.lower()\n",
    "        \n",
    "        # удаляем оставшиеся спецсимволы\n",
    "        token = re.sub(r'[^а-яёa-z]', '', token)\n",
    "        \n",
    "        if token and len(token) >= 2:\n",
    "            cleaned.append(token)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# регистрируем UDF\n",
    "clean_tokens_udf = udf(clean_tokens, ArrayType(StringType()))\n",
    "\n",
    "# применяем дополнительную очистку\n",
    "df_final_tokens = df_no_stopwords.withColumn(\n",
    "    \"words_final\",\n",
    "    clean_tokens_udf(col(\"words_without_stopwords\"))\n",
    ")\n",
    "\n",
    "# фильтруем отзывы с слишком маленьким количеством слов\n",
    "initial_count = df_final_tokens.count()\n",
    "df_final_tokens = df_final_tokens.filter(size(col(\"words_final\")) >= 3)\n",
    "final_count = df_final_tokens.count()\n",
    "\n",
    "print(f\"   После фильтрации (минимум 3 слова): {final_count:,} из {initial_count:,} отзывов\")\n",
    "print(f\"   Удалено: {initial_count - final_count:,} отзывов\")\n",
    "\n",
    "# анализ финальных токенов\n",
    "print(\"\\n   Итоговая статистика по токенам:\")\n",
    "final_stats = df_final_tokens.withColumn(\"final_word_count\", size(col(\"words_final\"))) \\\n",
    "                            .groupBy(\"sentiment\") \\\n",
    "                            .agg(\n",
    "                                avg(\"final_word_count\").alias(\"avg_final_words\"),\n",
    "                                stddev(\"final_word_count\").alias(\"std_final_words\"),\n",
    "                                min(\"final_word_count\").alias(\"min_final_words\"),\n",
    "                                max(\"final_word_count\").alias(\"max_final_words\"),\n",
    "                                sql_count(\"*\").alias(\"review_count\")\n",
    "                            ).orderBy(\"avg_final_words\", ascending=False)\n",
    "\n",
    "final_stats.show()\n",
    "\n",
    "print(\"\\n   Сохранение финальных подготовленных данных...\")\n",
    "df_final_tokens.select(\n",
    "    \"film_id\", \"review_num\", \"sentiment\", \"review_text\",\n",
    "    \"review_length\", \"word_count\", \"words_final\"\n",
    ").write.mode(\"overwrite\").parquet(\"data/processed/reviews_prepared_for_ml.parquet\")\n",
    "\n",
    "print(\"  Данные сохранены: data/processed/reviews_prepared_for_ml.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4a9ce",
   "metadata": {},
   "source": [
    "### TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a673c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Загрузка подготовленных данных...\n",
      "   Загружено отзывов: 109,998\n",
      "\n",
      "   а) Метод 1: HashingTF + IDF (рекомендуется для больших данных)\n",
      "   Обучение TF-IDF модели на 1024 фичах...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TF-IDF векторы созданы для 109,998 документов\n",
      "\n",
      "   б) Анализ TF-IDF векторов:\n",
      "\n",
      "   Статистика по TF-IDF векторам:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------------+------------------+------------+\n",
      "|sentiment|      avg_non_zero|     std_non_zero| avg_feature_value|review_count|\n",
      "+---------+------------------+-----------------+------------------+------------+\n",
      "|      neg|159.99520872012937|70.92134842708138|0.3337238906759899|       16697|\n",
      "|      pos|157.64652609368792| 72.0375654930883|0.3298302820759359|       72987|\n",
      "|      neu|154.97297430343605|73.95257612901256|0.3227918246243086|       20314|\n",
      "+---------+------------------+-----------------+------------------+------------+\n",
      "\n",
      "\n",
      "   в) Пример TF-IDF вектора:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):                                              \n",
      "  File \"/home/shoose/anaconda3/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "  File \"/home/shoose/anaconda3/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Фильм 841263, отзыв 86\n",
      "   Тональность: pos\n",
      "   Текст: С момента появления первых фильмов от 'Марвел' про...\n",
      "   Ненулевых фич: 338\n",
      "   Среднее значение фичи: 0.7634\n",
      "\n",
      "   г) Сохранение TF-IDF результатов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 409:================================>                       (7 + 5) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TF-IDF векторы сохранены: data/processed/reviews_tfidf_vectors.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "import numpy as np\n",
    "\n",
    "print(\"   Загрузка подготовленных данных...\")\n",
    "df_prepared = spark.read.parquet(\"data/processed/reviews_prepared_for_ml.parquet\")\n",
    "print(f\"   Загружено отзывов: {df_prepared.count():,}\")\n",
    "\n",
    "# HashingTF + IDF (эффективно для больших данных)\n",
    "print(\"\\n   а) Метод 1: HashingTF + IDF (рекомендуется для больших данных)\")\n",
    "\n",
    "# определяем размер фичевого пространства\n",
    "num_features = 1024  # 2^10 - хороший баланс\n",
    "\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"words_final\",\n",
    "    outputCol=\"raw_features\",\n",
    "    numFeatures=num_features\n",
    ")\n",
    "\n",
    "idf = IDF(\n",
    "    inputCol=\"raw_features\",\n",
    "    outputCol=\"tfidf_features\",\n",
    "    minDocFreq=2  # слово должно встречаться минимум в 2 документах\n",
    ")\n",
    "\n",
    "# создаем пайплайн\n",
    "pipeline_tfidf = Pipeline(stages=[hashing_tf, idf])\n",
    "\n",
    "print(f\"   Обучение TF-IDF модели на {num_features} фичах...\")\n",
    "tfidf_model = pipeline_tfidf.fit(df_prepared)\n",
    "df_tfidf = tfidf_model.transform(df_prepared)\n",
    "\n",
    "print(f\"   TF-IDF векторы созданы для {df_tfidf.count():,} документов\")\n",
    "\n",
    "print(\"\\n   б) Анализ TF-IDF векторов:\")\n",
    "\n",
    "# функция для анализа вектора\n",
    "def analyze_vector(vector):\n",
    "    if vector is None:\n",
    "        return (0, 0.0, 0.0, 0.0)\n",
    "    \n",
    "    values = vector.toArray()\n",
    "    non_zero = np.count_nonzero(values)\n",
    "    avg_value = np.mean(values) if len(values) > 0 else 0.0\n",
    "    max_value = np.max(values) if len(values) > 0 else 0.0\n",
    "    min_value = np.min(values) if len(values) > 0 else 0.0\n",
    "    \n",
    "    return (int(non_zero), float(avg_value), float(max_value), float(min_value))\n",
    "\n",
    "# регистрируем UDF\n",
    "analyze_vector_udf = udf(analyze_vector, \n",
    "                        StructType([\n",
    "                            StructField(\"non_zero\", IntegerType()),\n",
    "                            StructField(\"avg_value\", DoubleType()),\n",
    "                            StructField(\"max_value\", DoubleType()),\n",
    "                            StructField(\"min_value\", DoubleType())\n",
    "                        ]))\n",
    "\n",
    "# анализируем векторы\n",
    "df_vector_analysis = df_tfidf.withColumn(\"vector_stats\", analyze_vector_udf(col(\"tfidf_features\")))\n",
    "\n",
    "# извлекаем статистику\n",
    "df_vector_analysis = df_vector_analysis \\\n",
    "    .withColumn(\"non_zero_features\", col(\"vector_stats.non_zero\")) \\\n",
    "    .withColumn(\"avg_feature_value\", col(\"vector_stats.avg_value\")) \\\n",
    "    .withColumn(\"max_feature_value\", col(\"vector_stats.max_value\")) \\\n",
    "    .withColumn(\"min_feature_value\", col(\"vector_stats.min_value\"))\n",
    "\n",
    "print(\"\\n   Статистика по TF-IDF векторам:\")\n",
    "tfidf_stats = df_vector_analysis.groupBy(\"sentiment\").agg(\n",
    "    avg(\"non_zero_features\").alias(\"avg_non_zero\"),\n",
    "    stddev(\"non_zero_features\").alias(\"std_non_zero\"),\n",
    "    avg(\"avg_feature_value\").alias(\"avg_feature_value\"),\n",
    "    sql_count(\"*\").alias(\"review_count\")\n",
    ").orderBy(\"avg_non_zero\", ascending=False)\n",
    "\n",
    "tfidf_stats.show()\n",
    "\n",
    "print(\"\\n   в) Пример TF-IDF вектора:\")\n",
    "sample_vector = df_vector_analysis.select(\n",
    "    \"film_id\", \"review_num\", \"sentiment\",\n",
    "    \"non_zero_features\", \"avg_feature_value\",\n",
    "    substring(\"review_text\", 1, 50).alias(\"text_preview\")\n",
    ").limit(1).collect()[0]\n",
    "\n",
    "print(f\"   Фильм {sample_vector['film_id']}, отзыв {sample_vector['review_num']}\")\n",
    "print(f\"   Тональность: {sample_vector['sentiment']}\")\n",
    "print(f\"   Текст: {sample_vector['text_preview']}...\")\n",
    "print(f\"   Ненулевых фич: {sample_vector['non_zero_features']}\")\n",
    "print(f\"   Среднее значение фичи: {sample_vector['avg_feature_value']:.4f}\")\n",
    "\n",
    "# сохраняем TF-IDF векторы\n",
    "print(\"\\n   г) Сохранение TF-IDF результатов...\")\n",
    "df_tfidf.select(\n",
    "    \"film_id\", \"review_num\", \"sentiment\", \"review_text\",\n",
    "    \"tfidf_features\"\n",
    ").write.mode(\"overwrite\").parquet(\"data/processed/reviews_tfidf_vectors.parquet\")\n",
    "\n",
    "print(\"  TF-IDF векторы сохранены: data/processed/reviews_tfidf_vectors.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae7720",
   "metadata": {},
   "source": [
    "### Word2Vec для семантических эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5324623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Обучение Word2Vec модели...\n",
      "   Используем 10,000 отзывов для обучения\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Применение Word2Vec ко всем отзывам...\n",
      "   ✓ Word2Vec эмбеддинги созданы для 109,998 документов\n",
      "\n",
      "   а) Информация о Word2Vec модели:\n",
      "   Размер словаря: 77,406 слов\n",
      "   Размерность эмбеддингов: 100\n",
      "   Размер окна контекста: 3\n",
      "\n",
      "   б) Анализ эмбеддингов документов:\n",
      "\n",
      "   Статистика по эмбеддингам документов:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+------------+\n",
      "|sentiment|            avg_mean|             avg_std|review_count|\n",
      "+---------+--------------------+--------------------+------------+\n",
      "|      pos|-1.86855214510668...|0.043701505723708935|       72987|\n",
      "|      neu|-3.30615228639647...| 0.04337389870245893|       20314|\n",
      "|      neg|-5.01391402339131...| 0.04235123181779065|       16697|\n",
      "+---------+--------------------+--------------------+------------+\n",
      "\n",
      "\n",
      "   в) Сохранение Word2Vec результатов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/19 17:23:00 WARN TaskSetManager: Stage 597 contains a task of very large size (3079 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Модель сохранена (с перезаписью): models/word2vec_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/19 17:23:03 WARN TaskSetManager: Stage 601 contains a task of very large size (5850 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Эмбеддинги сохранены: data/processed/reviews_word2vec_embeddings.parquet\n",
      "   ✓ Векторы слов сохранены: data/processed/word_vectors.parquet\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "import numpy as np\n",
    "import builtins\n",
    "print(\"   Обучение Word2Vec модели...\")\n",
    "\n",
    "# используем подвыборку для обучения (Word2Vec требует много ресурсов)\n",
    "sample_size = builtins.min(10000, df_prepared.count())\n",
    "print(f\"   Используем {sample_size:,} отзывов для обучения\")\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    vectorSize=100,           # размерность эмбеддинга\n",
    "    windowSize=3,            # размер окна контекста\n",
    "    minCount=5,              # минимальная частота слова\n",
    "    maxIter=10,              # количество итераций\n",
    "    inputCol=\"words_final\",\n",
    "    outputCol=\"word2vec_embeddings\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "w2v_model = word2vec.fit(df_prepared.limit(sample_size))\n",
    "\n",
    "print(\"   Применение Word2Vec ко всем отзывам...\")\n",
    "df_w2v = w2v_model.transform(df_prepared)\n",
    "\n",
    "print(f\"   ✓ Word2Vec эмбеддинги созданы для {df_w2v.count():,} документов\")\n",
    "\n",
    "print(\"\\n   а) Информация о Word2Vec модели:\")\n",
    "print(f\"   Размер словаря: {w2v_model.getVectors().count():,} слов\")\n",
    "print(f\"   Размерность эмбеддингов: {word2vec.getVectorSize()}\")\n",
    "print(f\"   Размер окна контекста: {word2vec.getWindowSize()}\")\n",
    "\n",
    "print(\"\\n   б) Анализ эмбеддингов документов:\")\n",
    "\n",
    "def analyze_embedding(embedding):\n",
    "    if embedding is None:\n",
    "        return (0.0, 0.0, 0.0)\n",
    "    \n",
    "    values = np.array(embedding)\n",
    "    return (float(values.mean()), float(values.std()), float(values.max()))\n",
    "\n",
    "analyze_embedding_udf = udf(analyze_embedding,\n",
    "                           StructType([\n",
    "                               StructField(\"mean\", DoubleType()),\n",
    "                               StructField(\"std\", DoubleType()),\n",
    "                               StructField(\"max\", DoubleType())\n",
    "                           ]))\n",
    "\n",
    "df_embedding_analysis = df_w2v.withColumn(\"embedding_stats\", analyze_embedding_udf(col(\"word2vec_embeddings\")))\n",
    "\n",
    "df_embedding_analysis = df_embedding_analysis \\\n",
    "    .withColumn(\"embedding_mean\", col(\"embedding_stats.mean\")) \\\n",
    "    .withColumn(\"embedding_std\", col(\"embedding_stats.std\")) \\\n",
    "    .withColumn(\"embedding_max\", col(\"embedding_stats.max\"))\n",
    "\n",
    "print(\"\\n   Статистика по эмбеддингам документов:\")\n",
    "embedding_stats = df_embedding_analysis.groupBy(\"sentiment\").agg(\n",
    "    avg(\"embedding_mean\").alias(\"avg_mean\"),\n",
    "    avg(\"embedding_std\").alias(\"avg_std\"),\n",
    "    sql_count(\"*\").alias(\"review_count\")\n",
    ").orderBy(\"avg_mean\", ascending=False)\n",
    "\n",
    "embedding_stats.show()\n",
    "\n",
    "print(\"\\n   в) Сохранение Word2Vec результатов...\")\n",
    "\n",
    "w2v_model.write().overwrite().save(\"models/word2vec_model\") \n",
    "print(\"   ✓ Модель сохранена (с перезаписью): models/word2vec_model\")\n",
    "\n",
    "df_w2v.select(\n",
    "    \"film_id\", \"review_num\", \"sentiment\",\n",
    "    \"word2vec_embeddings\"\n",
    ").write.mode(\"overwrite\").parquet(\"data/processed/reviews_word2vec_embeddings.parquet\")\n",
    "print(\"   ✓ Эмбеддинги сохранены: data/processed/reviews_word2vec_embeddings.parquet\")\n",
    "\n",
    "w2v_model.getVectors().write.mode(\"overwrite\").parquet(\"data/processed/word_vectors.parquet\")\n",
    "print(\"   ✓ Векторы слов сохранены: data/processed/word_vectors.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
