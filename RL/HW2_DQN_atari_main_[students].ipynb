{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NDjJiqysoT-"
      },
      "source": [
        "# Реализация Deep Q-Network (DQN)\n",
        "\n",
        "В этом домашнем задании вам предстоит реализовать DQN — алгоритм аппроксимационного Q-обучения с использованием буфера воспроизведения опыта (experience replay) и целевых сетей (target networks) — и проверить, насколько лучше он будет работать.\n",
        "\n",
        "**Статьи для ознакомления:**\n",
        "\n",
        "[1] Оригинальная статья, 2013: https://arxiv.org/pdf/1312.5602.pdf\n",
        "\n",
        "[2] Расширенная версия, Nature, 2015: https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
        "\n",
        "[3] Rainbow, 2017: https://arxiv.org/pdf/1710.0228.pdf\n",
        "\n",
        "\n",
        "Референс задания взят из https://github.com/yandexdataschool/Practical_RL/tree/master/week04_approx_rl но адаптирован и доработан."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcLhaXMKsoT_"
      },
      "source": [
        "### Руководство по выполнению домашнего задания\n",
        "\n",
        "Это домашнее задание состоит из двух частей на выбор, которые помогут вам освоить обучение с подкреплением. Сдать нужно одну из них. Первая \"отладочная\" часть может помочь быстрее отладить код для основного ноутбука, так как задания и код сильно пересекаются, но обучение в отладочной среде занимает гораздо меньше времени.\n",
        "\n",
        "1. **Отладочный ноутбук (среда CartPole)**\n",
        "\n",
        "* Что это: Это первая и более простая часть задания. В ней используется среда CartPole, где агент учится балансировать шест.\n",
        "* Зачем начинать с него: Обучение здесь занимает всего несколько минут, что делает его идеальным для отладки вашего кода. Вы сможете быстро убедиться, что ваш алгоритм работает правильно, прежде чем переходить к более сложным задачам.\n",
        "* Оценка: За выполнение основных заданий в этом ноутбуке вы можете получить 16 баллов. С помощью бонусных заданий вы сможете добрать оставшиеся баллы (до 12 бонусных баллов).\n",
        "\n",
        "2. **Основной ноутбук (среда Atari)**\n",
        "\n",
        "* Что это: Это вторая, более сложная часть. Здесь вы будете работать со средой Atari, что требует от агента решения более комплексных задач.\n",
        "* Особенности: Обучение в этой среде занимает гораздо больше времени (около 2 часов), поэтому важно, чтобы ваш код был хорошо отлажен.\n",
        "* Оценка:\n",
        "    * Основные задания: За их успешное выполнение вы можете получить 20 баллов.\n",
        "    * Бонусные задания: Если вы выполните эти задания, вы можете получить до 15 баллов, которые будут добавлены к вашей итоговой оценке за весь курс.\n",
        "\n",
        "\n",
        "**Рекомендуемый порядок выполнения:**\n",
        "Начните с ноутбука CartPole, чтобы отладить алгоритм, а затем перенесите его в ноутбук Atari для получения максимального результата и дополнительных баллов.\n",
        "\n",
        "**Система получения баллов для наглядности преставлена табличкой (зелёным отмечены бонусы)**\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Инструкции по использованию ресурсов Colab:\n",
        "\n",
        "* После решения всех заданий **подключитесь к среде с GPU**: \"Среда выполнения\" ->  \"Сменить среду выполнения\" -> \"Графический процессор T4\". В среднем GPU **хватит на пару часов** (зависит от того, насколько часто вы пользуетесь колабом и от загруженности ресурсов гугла) -- должно хватить на обучение отлаженной модели до нужных баллов.\n",
        "* **Не тратьте ресурсы GPU на дебаг**, они могут быстро закончиться, включайте среды с GPU только для обучения готовых моделей\n",
        "* Можно сделать **несколько гугл-аккаунтов** и обучать на других аккаунтах, когда закончатся ресурсы GPU, либо попробовать через сутки на этом же аккаунте обучить снова.\n",
        "* Можно подключить диск, чтобы **сохранять веса и логи обученной модели**, чтобы не терять прогресс обния, когда коллаб перезапустится. Ниже мы реализовали такую возможность для вас.\n",
        "* Вкладки в Colab могут отключаться от бездействия. Чтобы так не было, **сделайте так, чтобы ваш ноутбук не отключался от бездействия** (Скачайте Amphetamin на macbook/ найдите \"питание и  спящий режим\" в настройках на windows и увеличить время перехода в спящий режим)"
      ],
      "metadata": {
        "id": "zP4sChPpPiJH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVo0UxTWsoT_"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    os.makedirs('dqn', exist_ok=True)\n",
        "    os.makedirs('test_td_loss', exist_ok=True)\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/atari_wrappers.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/utils.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/replay_buffer.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/framebuffer.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/analysis.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/dqn/logger.py -P dqn/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/test_td_loss/compute_td_loss.py -P test_td_loss/\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/requirements.txt\n",
        "\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# Этот код создает виртуальный дисплей для отрисовки игровых изображений.\n",
        "# Он не будет иметь эффекта, если ваша машина уже оснащена монитором.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8WoWe9DsoUA"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gym.register_envs(ale_py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GQBgViKsoUA"
      },
      "source": [
        "### Давайте поиграем в старые видеоигры\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/nerd.png)\n",
        "\n",
        "На этот раз мы применим аппроксимационное Q-обучение к игре Atari под названием Breakout. Это не самая сложная игра, но она определенно сложнее всего, что мы пробовали раньше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMpWd4pG5Z_E"
      },
      "source": [
        "**Это различные версии Breakout, предоставляемые Gymnasium:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RrQOZO65Z_E"
      },
      "outputs": [],
      "source": [
        "all_names = list(gym.envs.registry.keys())\n",
        "names_breakout = [name for name in all_names if \"Break\" in name]\n",
        "names_breakout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_zvw_31soUA"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"ALE/Breakout-v5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcKJ3AxJ5Z_F"
      },
      "source": [
        "Если вам интересно узнать больше о средах Atari в Gymnasium, пожалуйста, обратитесь к:\n",
        "- [4] Документация Gymnasium: https://gymnasium.farama.org/environments/atari/\n",
        "- [5] Более длинная статья: https://arxiv.org/abs/1709.06009\n",
        "- [6] Более короткая статья: https://www.ijcai.org/Proceedings/2018/0787.pdf\n",
        "\n",
        "На данный момент достаточно знать о средах v5 следующее:\n",
        "- Среды v5 рекомендуются к использованию.\n",
        "- `frame_skip=5`: агенту показывается каждый 5-й кадр, а выбранное действие выполняется в течение следующих 5 шагов.\n",
        "- Случайность вносится параметром `repeat_action_probability=0.25`: с этой вероятностью вместо выбранного действия выполняется предыдущее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT9BvasNsoUA"
      },
      "source": [
        "## Знакомство со средой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwN8jA0OsoUA"
      },
      "source": [
        "**Давайте посмотрим, как выглядят наблюдения (observations).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpFifj7B5Z_F"
      },
      "outputs": [],
      "source": [
        "env = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "plt.imshow(env.render())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LwatBe5Z_F"
      },
      "source": [
        "**Еще несколько наблюдений, полученных в результате случайных действий**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUZHU2HdsoUB"
      },
      "outputs": [],
      "source": [
        "env = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "\n",
        "n_cols = 5\n",
        "n_rows = 2\n",
        "fig = plt.figure(figsize=(16, 9))\n",
        "\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, row * n_cols + col + 1)\n",
        "        ax.imshow(env.render())\n",
        "        env.step(env.action_space.sample())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0WQX9B5Z_G"
      },
      "source": [
        "**Об игре:** У вас 5 жизней, и вы получаете очки за разрушение стены. Верхние кирпичи приносят больше очков, чем нижние. Доступно 4 действия: начать игру (нужно вызывать в начале и после каждой потери жизни), двигаться влево, двигаться вправо и ничего не делать.\n",
        "\n",
        "Существуют некоторые общие обертки, используемые для сред Atari."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp7cQ0S55Z_G"
      },
      "source": [
        "**Давайте посмотрим на значения действий:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXyJ34kC5Z_G"
      },
      "outputs": [],
      "source": [
        "env.unwrapped.get_action_meanings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO8CUhpg5Z_G"
      },
      "source": [
        "1. `NOOP` означает действие \"ничего не делать\".\n",
        "2. `RIGHT` и `LEFT` перемещают платформу в соответствующем направлении.\n",
        "3. `FIRE` выпускает мяч в начале каждой жизни.\n",
        "\n",
        "В этом задании мы обернем среду так, чтобы действие `FIRE` выполнялось автоматически в начале жизни. Это превратит действие `FIRE` в еще один `NOOP`.\n",
        "Также мы обернем среду так, чтобы эпизод длился одну жизнь вместо пяти.\n",
        "Эти преобразования не рекомендуются в статье [5], но они были сделаны в оригинальной статье [1] и помогут обучению сойтись быстрее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNt1fbnsoUB"
      },
      "source": [
        "**Давайте немного поиграем.**\n",
        "\n",
        "Обратите внимание на аргументы `zoom` и `fps` в функции `play`. Управление: A, D, пробел."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOIL47azsoUB"
      },
      "outputs": [],
      "source": [
        "# # Не работает в Colab.\n",
        "# Даже на локальном ноутбуке ломает рендеринг matplotlib. Поэтому рекомендуется перезапускать ноутбук после игры.\n",
        "# # Используйте клавишу Escape, чтобы продолжить.\n",
        "\n",
        "# from gymnasium.utils.play import play\n",
        "\n",
        "# play(env=gym.make(ENV_NAME, render_mode=\"rgb_array\"), zoom=4, fps=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Us8IAU5Z_G"
      },
      "source": [
        "## Обертки для среды (Wrapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE7UIgIa5Z_H"
      },
      "outputs": [],
      "source": [
        "def make_basic_env():\n",
        "    return gym.make(ENV_NAME, render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DPrxQuXsoUB"
      },
      "source": [
        "### Обработка игрового изображения\n",
        "\n",
        "Давайте проверим форму и тип данных наблюдения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JR-Q2_C5Z_H"
      },
      "outputs": [],
      "source": [
        "env = make_basic_env()\n",
        "obs, *_ = env.reset()\n",
        "obs.shape, obs.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig7CK9N45Z_H"
      },
      "source": [
        "Исходные изображения Atari большие, по умолчанию 210x160x3. Однако для обучения нам не нужен такой уровень детализации.\n",
        "\n",
        "Мы можем сэкономить много времени, предварительно обработав игровое изображение, включая:\n",
        "* Изменение размера до меньшей формы, 64x64 (или 84x84, что используется в литературе).\n",
        "* Преобразование в оттенки серого.\n",
        "* Обрезку нерелевантных частей изображения (верх, низ и края) [мы этого делать не будем].\n",
        "\n",
        "Изображения имеют тип `uint8`.\n",
        "`uint8` означает 8-битное беззнаковое целое число.\n",
        "Мы будем хранить 10^5 или 10^6 наблюдений в памяти (ОЗУ), поэтому обратим внимание на сохранение 8-битного типа после наших преобразований."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUidMC0M5Z_H"
      },
      "outputs": [],
      "source": [
        "def apply_gray_scale_wrap(env):\n",
        "    # С выбранными ниже значениями аргументов обертка gym.wrappers.AtariPreprocessing\n",
        "    # только преобразует изображения в оттенки серого и уменьшает их до screen_size\n",
        "    env = gym.wrappers.AtariPreprocessing(\n",
        "        env,\n",
        "        noop_max=0,  # значение по умолчанию 30 может быть вредным с FireResetEnv и frame_skip=5\n",
        "        frame_skip=1,  # frame_skip уже установлен на 5 внутри среды\n",
        "        terminal_on_life_loss=False,  # мы делаем это явно в обертке FireResetEnv\n",
        "        screen_size=84  # пожалуйста, используйте 84 (стандартное значение) или 64 (сэкономит вычисления и память)\n",
        "    )\n",
        "    return env\n",
        "\n",
        "\n",
        "env = make_basic_env()\n",
        "env = apply_gray_scale_wrap(env)\n",
        "\n",
        "obs, *_ = env.reset()\n",
        "\n",
        "assert obs.dtype == np.dtype('uint8')\n",
        "\n",
        "print(obs.shape, obs.dtype)\n",
        "plt.imshow(obs, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLzdkokC5Z_H"
      },
      "source": [
        "### Специфичные для Atari обертки\n",
        "\n",
        "Мы пытаемся немного упростить себе жизнь с помощью следующих оберток:\n",
        "1. `EpisodicLifeEnv`: делает сигнал о том, что потеря мяча — это плохо, более явным.\n",
        "2. `FireResetEnv`: с ней агенту не нужно выполнять специальное действие, чтобы выпустить мяч в начале жизни."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVYAneer5Z_H"
      },
      "outputs": [],
      "source": [
        "from dqn.atari_wrappers import FireResetEnv\n",
        "from dqn.atari_wrappers import EpisodicLifeEnv\n",
        "\n",
        "def apply_atary_specific_wrap(env):\n",
        "    env = EpisodicLifeEnv(env)\n",
        "    env = FireResetEnv(env)\n",
        "    return env\n",
        "\n",
        "env = make_basic_env()\n",
        "env = apply_gray_scale_wrap(env)\n",
        "env = apply_atary_specific_wrap(env)\n",
        "\n",
        "obs, *_ = env.reset()\n",
        "\n",
        "print(obs.shape, obs.dtype)\n",
        "plt.imshow(obs, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8Can9I5Z_I"
      },
      "source": [
        "### FrameStack (Стэк кадров)\n",
        "Чтобы сделать игру играбельной из одного наблюдения (обратите внимание на направление мяча), мы объединяем (стэкаем) 4 последовательных кадра:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzULFA905Z_I"
      },
      "outputs": [],
      "source": [
        "N_FRAMES_STACKED = 4\n",
        "\n",
        "def make_final_env(apply_frame_stack=True):\n",
        "    \"\"\"\n",
        "    Создает среду со всеми примененными обертками.\n",
        "    Среда предназначена для непосредственного использования в качестве входа для алгоритма RL.\n",
        "\n",
        "    apply_frame_stack=False может быть полезно для векторизованных сред, которые не требуются для этого задания.\n",
        "    \"\"\"\n",
        "    env = make_basic_env()\n",
        "    env = apply_gray_scale_wrap(env)\n",
        "    env = apply_atary_specific_wrap(env)\n",
        "    if apply_frame_stack:\n",
        "### ВАШ КОД\n",
        "        env = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "    return env\n",
        "\n",
        "\n",
        "env = make_final_env()\n",
        "\n",
        "obs, *_ = env.reset()\n",
        "print(f\"Форма: {obs.shape}, тип данных: {obs.dtype}, тип объекта Python: {type(obs)}\")\n",
        "for _ in range(N_FRAMES_STACKED - 1):\n",
        "    obs, *_ = env.step(env.action_space.sample())\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"Кадры, слева направо: от старых к новым. Мяч падает.\")\n",
        "_, axes = plt.subplots(figsize=(len(obs) * 3, 4), ncols=len(obs))\n",
        "for ax, frame in zip(axes, obs):\n",
        "    ax.imshow(frame, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbvBX7HR5Z_I"
      },
      "source": [
        "**Это окончательная версия среды, на которой мы будем обучать RL-агента.**\n",
        "\n",
        "**Давайте обсудим представление наблюдения.**\n",
        "Наблюдение — это стэк из 4 кадров в оттенках серого с уменьшенным разрешением.\n",
        "Память (ОЗУ, RAM) — это очень востребованный ресурс в этой задаче. Поэтому:\n",
        "1. Мы используем тип данных `uint8` вместо `float32`, на котором будет работать нейронная сеть.\n",
        "2. Мы не представляем их как `numpy.ndarray`. Вместо этого `gym.wrappers.FrameStack` использует **LazyFrames**. Два последовательных наблюдения делят 3 из 4 кадров. `LazyFrames` используют этот факт для экономии памяти.\n",
        "Когда мы подаем наблюдения в нейронные сети, мы должны помнить о масштабировании их в диапазон `[0, 1]`. Мы реализуем масштабирование как первый слой нейронной сети, но об этом позже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4j7ODTT5Z_I"
      },
      "source": [
        "**Мяч падает, но это трудно заметить. Давайте определим функцию для рендеринга более понятных для человека изображений:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbWAOBJq5Z_I"
      },
      "outputs": [],
      "source": [
        "from gym.wrappers.frame_stack import LazyFrames\n",
        "def merge_frame_stack_to_plot(frame_stack_obs: np.ndarray| LazyFrames):\n",
        "    \"\"\"\n",
        "    Вспомогательная функция для отображения стэка кадров как одного понятного для человека изображения.\n",
        "\n",
        "    Более яркие пиксели — более новые, бледные — более старые.\n",
        "    Движение происходит от бледного к яркому.\n",
        "\n",
        "    Примечание! Эта функция предназначена для удобства человеческого зрения и НЕ должна использоваться как часть\n",
        "    предобработки данных для агента Reinforcement Learning.\n",
        "    \"\"\"\n",
        "    weights = np.ones(frame_stack_obs.shape[0], dtype=float)\n",
        "    weights[-1] += weights.sum()\n",
        "    weights /= weights.sum()\n",
        "    result = (weights[:, None, None] * np.array(frame_stack_obs)).sum(0)\n",
        "    return result\n",
        "\n",
        "\n",
        "obs_joint = merge_frame_stack_to_plot(obs)\n",
        "plt.imshow(obs_joint,  cmap='grey')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "you8rXt95Z_I"
      },
      "source": [
        "Надеюсь, так лучше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_pwrFpV5Z_I"
      },
      "outputs": [],
      "source": [
        "N_ACTIONS = env.action_space.n\n",
        "STATE_SHAPE = env.observation_space.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iJM3IAwsoUB"
      },
      "source": [
        "**Давайте посмотрим, можно ли еще играть в игру после применения оберток.**\n",
        "Во время игры кажется, что обертка `EpisodicLifeEnv` не работает, но на самом деле это не так (потому что после потери жизни новый мяч запускается автоматически — это означает, что обертка `FireResetEnv` понимает, что начался новый эпизод).\n",
        "\n",
        "**На данный момент не поддерживается.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhiOKsQvsoUC"
      },
      "source": [
        "## DQN как он есть (15 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspwJFiGsoUC"
      },
      "source": [
        "### Построение сети и агента (7 баллов)\n",
        "\n",
        "Теперь нам нужно построить нейронную сеть, которая может отображать изображения в Q-значения состояний. Эта сеть будет вызываться на каждом шаге агента, так что лучше, чтобы это была не ResNet-152, если у вас нет нескольких GPU. Вместо этого можно использовать свертки с шагом (strided convolutions) и небольшим количеством признаков, чтобы сэкономить время и память.\n",
        "\n",
        "Вы можете создать любую архитектуру, но ниже на диаграммах вы найдете пару примеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbZIucfksoUC"
      },
      "source": [
        "**Дуэльная сеть (Dueling Network):**\n",
        "Статья: https://arxiv.org/pdf/1511.06581.pdf\n",
        "$$Q_{\\theta}(s, a) = V_{\\eta}(f_{\\xi}(s)) + A_{\\psi}(f_{\\xi}(s), a) - \\frac{\\sum_{a'}A_{\\psi}(f_{\\xi}(s), a')}{N_{actions}},$$\n",
        "где $\\xi$, $\\eta$ и $\\psi$ — это, соответственно, параметры\n",
        "общего энкодера $f_\\xi$, потока ценности $V_\\eta$ и потока преимущества $A_\\psi$; а $\\theta = \\{\\xi, \\eta, \\psi\\}$ — их объединение.\n",
        "\n",
        "Вот как это выглядит:\n",
        "\n",
        "Простая версия, ожидает height=width=64\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/week04_approx_rl/img/dueling_basic.png)\n",
        "\n",
        "Nature DQN ([2]), ожидает height=width=84\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/week04_approx_rl/img/dueling_nature.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPPmY6wIsoUC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EajHS-Gj5Z_J"
      },
      "source": [
        "Эти константы будут полезны"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuNpsuuI5Z_K"
      },
      "outputs": [],
      "source": [
        "N_ACTIONS, N_FRAMES_STACKED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_9xQK5L5Z_K"
      },
      "outputs": [],
      "source": [
        "class ConvBackbone(nn.Sequential):\n",
        "    \"\"\"\n",
        "    Сверточная часть модели DQN.\n",
        "    Пожалуйста, не думайте здесь о масштабировании входа: это будет реализовано ниже.\n",
        "    \"\"\"\n",
        "    def __init__(self, c_in: int = N_FRAMES_STACKED) -> None:\n",
        "### ВАШ КОД\n",
        "        super().__init__(\n",
        "            nn.Conv2d(...),\n",
        "            nn.ReLU(),\n",
        "            ...\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "\n",
        "class DuelingDqnHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Реализует логику Dueling DQN.\n",
        "    Пожалуйста, не думайте здесь о масштабировании градиента: это будет реализовано ниже.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_actions, inp_size=64 * 7 * 7, hidden_size=512) -> None:\n",
        "        super().__init__()\n",
        "### ВАШ КОД\n",
        "        self.adv_stream = nn.Sequential(\n",
        "            nn.Linear(...),\n",
        "            ...\n",
        "        )\n",
        "        self.value_stream = nn.Sequential(\n",
        "            ...\n",
        "        )\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.ndim == 2, x.shape  # (batch_size, n_features)\n",
        "        #при подсчёте среднего помните о том, что x - это батч данных\n",
        "### ВАШ КОД\n",
        "        ...\n",
        "        return q_values\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDFKE5Yv5Z_K"
      },
      "source": [
        "Проведем простой тест для архитектуры сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz4FMyQp5Z_K"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test_network_part_shapes(backbone, head):\n",
        "    batch_size = 3\n",
        "    env = make_final_env()\n",
        "    s, _ = env.reset()\n",
        "    inp = torch.rand(batch_size, *s.shape, dtype=torch.float32)\n",
        "\n",
        "    features = backbone(inp)\n",
        "    qvalues = head(features)\n",
        "\n",
        "    assert features.ndim == 2, features.shape\n",
        "    assert features.shape[0] == batch_size, features.shape\n",
        "\n",
        "    assert qvalues.ndim == 2, qvalues.shape\n",
        "    assert qvalues.shape[0] == batch_size, qvalues.shape\n",
        "    assert qvalues.shape[1] == N_ACTIONS, qvalues.shape\n",
        "\n",
        "    print(\"Тест пройден!\")\n",
        "\n",
        "test_network_part_shapes(\n",
        "    backbone=ConvBackbone(N_FRAMES_STACKED),\n",
        "    head=DuelingDqnHead(N_ACTIONS, inp_size=3136),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsoWJ_rS5Z_K"
      },
      "source": [
        "**Теперь соберем полную модель.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Er-SLx15Z_K"
      },
      "outputs": [],
      "source": [
        "MAX_UINT_8 = 2 ** 8 - 1\n",
        "\n",
        "\n",
        "class InputScaler(nn.Module):\n",
        "    def __init__(self, mult=1 / MAX_UINT_8):\n",
        "        super().__init__()\n",
        "        self.mult = mult\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x.float() * self.mult\n",
        "\n",
        "\n",
        "class GradScalerFunctional(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    torch.autograd.Function работает как Identity на прямом проходе\n",
        "    и масштабирует градиент на scale_factor на обратном проходе.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, scale_factor):\n",
        "        ctx.scale_factor = scale_factor\n",
        "        return input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        scale_factor = ctx.scale_factor\n",
        "        grad_input = grad_output * scale_factor\n",
        "        return grad_input, None\n",
        "\n",
        "\n",
        "class GradScaler(nn.Module):\n",
        "    \"\"\"\n",
        "    nn.Module, инкапсулирующий GradScalerFunctional\n",
        "    \"\"\"\n",
        "    def __init__(self, scale_factor: float):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        return GradScalerFunctional.apply(x, self.scale_factor)\n",
        "\n",
        "\n",
        "class DQNetworkDueling(nn.Sequential):\n",
        "    def __init__(self, c_in: int, n_actions: int) -> None:\n",
        "        input_scaler = InputScaler()  # входы поступают из диапазона uint8\n",
        "        backbone = ConvBackbone(c_in=c_in)\n",
        "        grad_scaler = GradScaler(1 / 2**0.5)  # Dueling DQN предлагает масштабировать градиент на 1 / sqrt(2)\n",
        "        head = DuelingDqnHead(n_actions=n_actions, inp_size=3136)\n",
        "        super().__init__(input_scaler, backbone, grad_scaler, head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHI4jJob5Z_K"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test_network_shapes(model):\n",
        "    batch_size = 3\n",
        "    env = make_final_env()\n",
        "    s, _ = env.reset()\n",
        "    inp = torch.tensor(np.array(s)[None], dtype=torch.uint8).expand(batch_size, -1, -1, -1)\n",
        "\n",
        "    qvalues = model(inp)\n",
        "\n",
        "    assert qvalues.ndim == 2, qvalues.shape\n",
        "    assert qvalues.shape[0] == batch_size, qvalues.shape\n",
        "    assert qvalues.shape[1] == N_ACTIONS, qvalues.shape\n",
        "\n",
        "    print(\"Тест пройден!\")\n",
        "\n",
        "test_network_shapes(model=DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyjCrS8W5Z_L"
      },
      "source": [
        "**Теперь обернем нашу модель в класс `Agent`.**\n",
        "Он будет реализовывать эпсилон-жадную политику на массивах numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-dq7i5p5Z_L"
      },
      "outputs": [],
      "source": [
        "class DQNAgent(nn.Module):\n",
        "    \"\"\"\n",
        "    Эпсилон-жадная политика с оценщиком Q-значений на основе torch.nn.Module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, q_network: nn.Module, epsilon=1) -> None:\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.q_network = q_network\n",
        "\n",
        "    def forward(self, state_t):\n",
        "        \"\"\"\n",
        "        принимает наблюдение агента (тензор), возвращает q-значения (тензор)\n",
        "        :param state_t: батч из 4-кадровых буферов, форма = [batch_size, 4, h, w]\n",
        "        \"\"\"\n",
        "### ВАШ КОД\n",
        "        qvalues =...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "        return qvalues\n",
        "\n",
        "    @torch.no_grad()  # здесь нам не нужен автоград, так что сэкономим вычисления\n",
        "    def get_qvalues(self, states: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        похоже на forward, но работает с массивами numpy, а не с тензорами\n",
        "        \"\"\"\n",
        "        model_device = next(self.parameters()).device\n",
        "        states_pt = torch.tensor(\n",
        "            np.array(states), device=model_device, dtype=torch.uint8\n",
        "        )\n",
        "### ВАШ КОД\n",
        "        qvalues_pt = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "        qvalues = qvalues_pt.data.cpu().numpy()\n",
        "        return qvalues\n",
        "\n",
        "    def sample_actions_by_qvalues(self, qvalues: np.ndarray, greedy: bool = False) -> np.ndarray:\n",
        "        \"\"\"выбирает действия на основе q-значений. Использует эпсилон-жадную стратегию исследования.\"\"\"\n",
        "### ВАШ КОД\n",
        "        ...\n",
        "        return epsilon_greedy_actions\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    def sample_actions(self, states: np.ndarray, greedy: bool = False) -> np.ndarray:\n",
        "        qvalues = self.get_qvalues(states)\n",
        "        actions = self.sample_actions_by_qvalues(qvalues, greedy=greedy)\n",
        "        return actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czLObf-G5Z_L"
      },
      "outputs": [],
      "source": [
        "test_network_shapes(\n",
        "    model=DQNAgent(DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUFMLKX1soUC"
      },
      "outputs": [],
      "source": [
        "agent = DQNAgent(\n",
        "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
        "    epsilon=0.5\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbsIT2EdsoUC"
      },
      "source": [
        "Теперь давайте проверим нашего агента, чтобы убедиться, что он не вызывает ошибок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZR3qE2esoUC"
      },
      "outputs": [],
      "source": [
        "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000, seed=None):\n",
        "    \"\"\" Играет n_games полных игр. Если greedy=True, выбирает действия как argmax(q-значений). Возвращает среднюю награду. \"\"\"\n",
        "    rewards = []\n",
        "    for _ in range(n_games):\n",
        "        s, _ = env.reset(seed=seed)\n",
        "        reward = 0\n",
        "        for _ in range(t_max):\n",
        "            action = agent.sample_actions(np.array(s)[None], greedy=greedy)[0]\n",
        "            s, r, terminated, truncated, _ = env.step(action)\n",
        "            reward += r\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        rewards.append(reward)\n",
        "    return np.mean(rewards)\n",
        "\n",
        "print(evaluate(env, agent, n_games=1, greedy=False))\n",
        "print(evaluate(env, agent, n_games=1, greedy=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BiRixA-soUC"
      },
      "source": [
        "### Буфер воспроизведения опыта (Experience Replay)\n",
        "Для этого задания мы предоставляем вам готовый буфер воспроизведения опыта.\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTBZo5BVsoUC"
      },
      "source": [
        "Интерфейс довольно прост:\n",
        "* `exp_replay.add(obs, act, rw, next_obs, done)` - сохраняет кортеж (s, a, r, s', done) в буфер\n",
        "* `exp_replay.sample(batch_size)` - возвращает наблюдения, действия, награды, следующие наблюдения и флаги завершения для `batch_size` случайных сэмплов.\n",
        "* `len(exp_replay)` - возвращает количество элементов, хранящихся в буфере."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"Создаёт буфер воспроизведения.\n",
        "        Параметры\n",
        "        ----------\n",
        "        size: int\n",
        "            Максимальное количество переходов, которые можно хранить в буфере.\n",
        "            При переполнении буфера старые записи удаляются.\n",
        "        \"\"\"\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "        self._next_idx = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "\n",
        "        if self._next_idx >= len(self._storage):\n",
        "            self._storage.append(data)\n",
        "        else:\n",
        "            self._storage[self._next_idx] = data\n",
        "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
        "\n",
        "    def _encode_sample(self, idxes):\n",
        "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
        "        for i in idxes:\n",
        "            data = self._storage[i]\n",
        "            obs_t, action, reward, obs_tp1, done = data\n",
        "            obses_t.append(np.asarray(obs_t))\n",
        "            actions.append(np.asarray(action))\n",
        "            rewards.append(reward)\n",
        "            obses_tp1.append(np.asarray(obs_tp1))\n",
        "            dones.append(done)\n",
        "        return (\n",
        "            np.array(obses_t),\n",
        "            np.array(actions),\n",
        "            np.array(rewards),\n",
        "            np.array(obses_tp1),\n",
        "            np.array(dones),\n",
        "        )\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Выбирает случайную партию переходов из буфера.\n",
        "        Параметры\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            Сколько переходов нужно выбрать.\n",
        "        Возвращает\n",
        "        -------\n",
        "        obs_batch: np.array\n",
        "            партия наблюдений\n",
        "        act_batch: np.array\n",
        "            партия действий, выполненных в состоянии obs_batch\n",
        "        rew_batch: np.array\n",
        "            вознаграждения, полученные в результате выполнения act_batch\n",
        "        next_obs_batch: np.array\n",
        "            следующие наблюдения после выполнения act_batch\n",
        "        done_mask: np.array\n",
        "            done_mask[i] = 1, если выполнение act_batch[i] привело к завершению эпизода,\n",
        "            и 0 в противном случае.\n",
        "        \"\"\"\n",
        "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
        "        return self._encode_sample(idxes)\n"
      ],
      "metadata": {
        "id": "jhiU1snh9G-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydi0KK9LsoUC"
      },
      "outputs": [],
      "source": [
        "exp_replay = ReplayBuffer(10)\n",
        "\n",
        "for _ in range(30):\n",
        "    exp_replay.add(env.reset()[0], env.action_space.sample(), 1.0, env.reset()[0], done=False)\n",
        "\n",
        "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(5)\n",
        "\n",
        "assert len(exp_replay) == 10, \"Размер буфера должен быть 10, так как это его максимальная вместимость\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Play and record (3 балла)"
      ],
      "metadata": {
        "id": "vE20hVIuWdOl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDpumbdT5Z_M"
      },
      "source": [
        "**Функция `play_and_record`, определенная ниже, является основным способом взаимодействия агента со средой во время обучения.**\n",
        "\n",
        "Ранее мы обучали RL-алгоритмы на целых эпизодах.\n",
        "На этот раз мы будем поддерживать среду в постоянном рабочем состоянии и получать небольшие порции взаимодействий с ней.\n",
        "\n",
        "Агент выполняет несколько действий (4 действия в [2] и [3]), соответствующие кортежи (s, a, r, s', terminated) помещаются в буфер воспроизведения.\n",
        "Каждый раз, когда эпизод заканчивается (т.е. `truncated` или `terminated`), среда сбрасывается, и процедура продолжается как обычно.\n",
        "\n",
        "Чтобы сделать первый шаг в постоянно работающей среде, агенту необходимо знать ее состояние. В этом и заключается смысл аргумента `initial_state` функции.\n",
        "\n",
        "Стоит отметить, что агент не обучается на свежих кортежах немедленно. Агент обучается на выборках, которые извлекаются из буфера.\n",
        "\n",
        "**Примечание по реализации:**\n",
        "Мы определяем протокол `ActionSampler`. Его цель — позволить функции `play_and_record` принимать не только экземпляры класса `DQNAgent`, но и любой объект, который может выбирать действия."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEXv69KWsoUC"
      },
      "outputs": [],
      "source": [
        "from typing import Protocol, Reversible\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ActionSampler(Protocol):\n",
        "    \"\"\"\n",
        "    Протокол, определяющий вызываемый объект, который выбирает действия из состояний\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self, states: np.ndarray, greedy: bool = False\n",
        "    ) -> np.ndarray: ...\n",
        "\n",
        "\n",
        "class RandomActionSampler:\n",
        "    \"\"\"\n",
        "    Этот класс понадобится нам для заполнения буфера начальными 50-200 тыс. наблюдений из случайной политики.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, action_space) -> None:\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def __call__(\n",
        "        self, states: gym.wrappers.stateful_observation.FrameStackObservation, greedy: bool = False\n",
        "    ) -> np.ndarray:\n",
        "        return np.array([self.action_space.sample() for _ in states])\n",
        "\n",
        "\n",
        "class DqnActionSampler:\n",
        "    \"\"\"\n",
        "    DQNAgent работает с батчами входов np.ndarray.\n",
        "    Этот класс использует DQNAgent для выбора действий из одиночных наблюдений LazyFrames.\n",
        "\n",
        "    Это будет эпсилон-жадный сэмплер.\n",
        "    Можно также определить жадный сэмплер, но он нам не понадобится.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent: DQNAgent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def __call__(\n",
        "        self, states: gym.wrappers.stateful_observation.FrameStackObservation, greedy: bool = False\n",
        "    ) -> np.ndarray:\n",
        "### ВАШ КОД\n",
        "        return  ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def play_and_record(\n",
        "    initial_state: np.ndarray,\n",
        "    action_sampler: ActionSampler,\n",
        "    env,\n",
        "    exp_replay,\n",
        "    n_steps=1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Играет в игру ровно n_steps, записывает каждый переход (s,a,r,s', done) в буфер.\n",
        "    Каждый раз, когда игра заканчивается из-за завершения или усечения, добавляет запись с done=terminated и сбрасывает среду.\n",
        "    Гарантируется, что при передаче в эту функцию у среды terminated=False.\n",
        "\n",
        "    ПОЖАЛУЙСТА, НЕ СБРАСЫВАЙТЕ СРЕДУ, ЕСЛИ done=False\n",
        "\n",
        "    :возвращает: сумму наград за время игры и состояние, в котором осталась среда\n",
        "    \"\"\"\n",
        "    s = initial_state\n",
        "    sum_rewards = 0\n",
        "\n",
        "### ВАШ КОД\n",
        "    for _ in range(n_steps):\n",
        "        ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    return sum_rewards, s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2VC6z685Z_M"
      },
      "outputs": [],
      "source": [
        "def test_play_and_record(action_sampler):\n",
        "    exp_replay = ReplayBuffer(10_000)\n",
        "\n",
        "    state, _ = env.reset()\n",
        "\n",
        "    play_and_record(state, action_sampler, env, exp_replay, n_steps=1000);\n",
        "\n",
        "    assert len(exp_replay) == 1000, \\\n",
        "        \"play_and_record должен был добавить ровно 1000 шагов, \" \\\n",
        "        \"но вместо этого добавил %i\" % len(exp_replay)\n",
        "    is_dones = list(zip(*exp_replay._storage))[-1]\n",
        "\n",
        "    assert 0 < np.mean(is_dones) < 0.1, \\\n",
        "        \"Пожалуйста, убедитесь, что вы перезапускаете игру, когда done=True, и \" \\\n",
        "        \"правильно записываете is_done в буфер. Получена доля is_done=%f за \" \\\n",
        "        \"%i шагов. [Если вы думаете, что это просто не повезло, просто перезапустите тест]\" % (\n",
        "            np.mean(is_dones), len(exp_replay))\n",
        "\n",
        "    for _ in range(100):\n",
        "        obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
        "        assert obs_batch.shape == next_obs_batch.shape == (10,) + STATE_SHAPE\n",
        "        assert act_batch.shape == (10,), \\\n",
        "            \"батч действий должен иметь форму (10,), а не %s\" % str(act_batch.shape)\n",
        "        assert reward_batch.shape == (10,), \\\n",
        "            \"батч наград должен иметь форму (10,), а не %s\" % str(reward_batch.shape)\n",
        "        assert is_done_batch.shape == (10,), \\\n",
        "            \"батч is_done должен иметь форму (10,), а не %s\" % str(is_done_batch.shape)\n",
        "        assert [int(i) in (0, 1) for i in is_dones], \\\n",
        "            \"is_done должен быть строго True или False\"\n",
        "        assert [0 <= a < N_ACTIONS for a in act_batch], \"действия должны быть в диапазоне [0, n_actions)\"\n",
        "\n",
        "    print(\"Отлично!\")\n",
        "\n",
        "\n",
        "print(\"Случайный сэмплер:\")\n",
        "test_play_and_record(RandomActionSampler(env.action_space))\n",
        "print(\"DQN сэмплер:\")\n",
        "test_play_and_record(DqnActionSampler(agent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5zyryPOsoUF"
      },
      "source": [
        "### Целевые сети (Target Networks)\n",
        "\n",
        "Мы также используем так называемую \"целевую сеть\" — копию весов нейронной сети для вычисления целевых Q-значений:\n",
        "\n",
        "Сама сеть является точной копией сети агента, но ее параметры не обучаются. Вместо этого они периодически копируются из основной сети агента.\n",
        "\n",
        "$$ Q_{reference}(s,a) = r + \\gamma \\cdot \\max _{a'} Q_{target}(s',a') $$\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/target_net.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oc78NSo5Z_M"
      },
      "outputs": [],
      "source": [
        "target_network = DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS).to(device)\n",
        "target_network.load_state_dict(agent.q_network.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2idY8QX0soUF"
      },
      "source": [
        "### Обучение с Q-learning, TD-loss (5 баллов = 3 дефолтный TD + 2 double TD)\n",
        "Здесь мы напишем функцию, аналогичную `agent.update` из табличного Q-обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k46MPwwwsoUF"
      },
      "source": [
        "Вычислите временную разницу (TD-ошибку) для Q-обучения:\n",
        "\n",
        "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
        "\n",
        "Где $Q_{reference}$ определяется как\n",
        "\n",
        "$$ Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
        "\n",
        "Здесь\n",
        "* $Q_{target}(s',a')$ обозначает Q-значение следующего состояния и следующего действия, предсказанное __целевой сетью (target_network)__\n",
        "* $s, a, r, s'$ — это текущее состояние, действие, награда и следующее состояние соответственно\n",
        "* $\\gamma$ — это фактор дисконтирования.\n",
        "\n",
        "\n",
        "__Примечание 1:__ ниже приведен пример входных данных. Не стесняйтесь экспериментировать с ним, прежде чем писать функцию.\n",
        "\n",
        "__Примечание 2:__ `compute_td_loss` — это основной источник ошибок в этом домашнем задании. Мы постарались покрыть его тестами, но если награда не улучшается, часто помогает пройтись по коду построчно [с резиновой уточкой](https://rubberduckdebugging.com/).\n",
        "\n",
        "**Двойной DQN (Double DQN)**\n",
        "\n",
        "$$ Q_{reference}(s,a) = r(s, a) + \\gamma \\cdot\n",
        "Q_{target}(s',argmax_{a'}Q_\\theta(s', a')) $$\n",
        "\n",
        "Мы будем использовать Double DQN для обучения, но **просим вас реализовать оба** метода, чтобы почувствовать разницу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V02HcUYasoUG"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss_on_tensors(\n",
        "    states: torch.Tensor,  # (batch_size, *state_shape)\n",
        "    actions: torch.Tensor,  # (batch_size,)\n",
        "    rewards: torch.Tensor,  # (batch_size,)\n",
        "    next_states: torch.Tensor,  # (batch_size, *state_shape)\n",
        "    is_done: torch.Tensor,  # (batch_size,), torch.bool\n",
        "    agent: nn.Module,\n",
        "    target_network: nn.Module,\n",
        "    gamma: float = 0.99,\n",
        "    check_shapes=False,\n",
        "):\n",
        "    predicted_qvalues = agent(states)  # форма: [batch_size, n_actions]\n",
        "    assert is_done.dtype is torch.bool\n",
        "\n",
        "    # вычисляем q-значения для всех действий в следующих состояниях\n",
        "    with torch.no_grad():\n",
        "### ВАШ КОД\n",
        "        predicted_next_qvalues_target = ... # форма: [batch_size, n_actions]\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    # выбираем q-значения для выбранных действий\n",
        "    predicted_qvalues_for_actions = predicted_qvalues[\n",
        "        range(len(actions)), actions\n",
        "    ]  # форма: [batch_size]\n",
        "\n",
        "    # вычисляем V*(next_states) используя предсказанные q-значения следующих состояний\n",
        "### ВАШ КОД\n",
        "    next_state_values = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    if check_shapes:\n",
        "        assert (\n",
        "            next_state_values.dim() == 1\n",
        "            and next_state_values.shape[0] == states.shape[0]\n",
        "        ), \"должно предсказываться одно значение на состояние\"\n",
        "        assert not next_state_values.requires_grad\n",
        "\n",
        "    # вычисляем \"целевые q-значения\" для ошибки - это то, что в квадратных скобках в формуле выше.\n",
        "    # в последнем состоянии используем упрощенную формулу: Q(s,a) = r(s,a), так как s' не существует\n",
        "### ВАШ КОД\n",
        "    target_qvalues_for_actions = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    # среднеквадратичная ошибка для минимизации\n",
        "    loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n",
        "\n",
        "    if check_shapes:\n",
        "        assert (\n",
        "            predicted_next_qvalues_target.data.dim() == 2\n",
        "        ), \"убедитесь, что вы предсказали q-значения для всех действий в следующем состоянии\"\n",
        "        assert (\n",
        "            next_state_values.data.dim() == 1\n",
        "        ), \"убедитесь, что вы вычислили V(s') как максимум только по оси действий, а не по всем осям\"\n",
        "        assert (\n",
        "            target_qvalues_for_actions.data.dim() == 1\n",
        "        ), \"что-то не так с целевыми q-значениями, они должны быть вектором\"\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujVuSF9z5Z_N"
      },
      "outputs": [],
      "source": [
        "from test_td_loss.compute_td_loss import test_is_done_is_used, test_compute_td_loss_vanilla\n",
        "\n",
        "test_compute_td_loss_vanilla(compute_td_loss_on_tensors)\n",
        "print(\"Отлично!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cJnofuR5Z_N"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss_on_tensors_double(\n",
        "    states: torch.Tensor,  # (batch_size, *state_shape)\n",
        "    actions: torch.Tensor,  # (batch_size,)\n",
        "    rewards: torch.Tensor,  # (batch_size,)\n",
        "    next_states: torch.Tensor,  # (batch_size, *state_shape)\n",
        "    is_done: torch.Tensor,  # (batch_size,), torch.bool\n",
        "    agent: nn.Module,\n",
        "    target_network: nn.Module,\n",
        "    gamma: float = 0.99,\n",
        "    check_shapes=False,\n",
        "):\n",
        "    predicted_qvalues = agent(states)  # форма: [batch_size, n_actions]\n",
        "    assert is_done.dtype is torch.bool\n",
        "\n",
        "    # вычисляем q-значения для всех действий в следующих состояниях\n",
        "    with torch.no_grad():\n",
        "### ВАШ КОД\n",
        "        predicted_next_qvalues_agent = ...\n",
        "        predicted_next_qvalues_target = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    # выбираем q-значения для выбранных действий\n",
        "    predicted_qvalues_for_actions = predicted_qvalues[\n",
        "        range(len(actions)), actions\n",
        "    ]  # форма: [batch_size]\n",
        "\n",
        "    # вычисляем V*(next_states) используя предсказанные q-значения следующих состояний\n",
        "### ВАШ КОД\n",
        "    next_state_values = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    if check_shapes:\n",
        "        assert (\n",
        "            next_state_values.dim() == 1\n",
        "            and next_state_values.shape[0] == states.shape[0]\n",
        "        ), \"должно предсказываться одно значение на состояние\"\n",
        "        assert not next_state_values.requires_grad\n",
        "\n",
        "    # вычисляем \"целевые q-значения\" для ошибки - это то, что в квадратных скобках в формуле выше.\n",
        "    # в последнем состоянии используем упрощенную формулу: Q(s,a) = r(s,a), так как s' не существует\n",
        "### ВАШ КОД\n",
        "    target_qvalues_for_actions = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "    # среднеквадратичная ошибка для минимизации\n",
        "    loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n",
        "\n",
        "    if check_shapes:\n",
        "        assert (\n",
        "            predicted_next_qvalues_target.data.dim() == 2\n",
        "        ), \"убедитесь, что вы предсказали q-значения для всех действий в следующем состоянии\"\n",
        "        assert (\n",
        "            next_state_values.data.dim() == 1\n",
        "        ), \"убедитесь, что вы вычислили V(s') как максимум только по оси действий, а не по всем осям\"\n",
        "        assert (\n",
        "            target_qvalues_for_actions.data.dim() == 1\n",
        "        ), \"что-то не так с целевыми q-значениями, они должны быть вектором\"\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tVGJ2rR5Z_N"
      },
      "outputs": [],
      "source": [
        "from test_td_loss.compute_td_loss import test_compute_td_loss_double\n",
        "\n",
        "test_compute_td_loss_double(compute_td_loss_on_tensors_double)\n",
        "print(\"Отлично!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOXuotUA5Z_O"
      },
      "source": [
        "**Следующая функция работает с `np.ndarray`: она преобразует свои входы в `torch.Tensor` и вызывает функцию для тензоров**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVMaW9Ui5Z_O"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss(\n",
        "    states,\n",
        "    actions,\n",
        "    rewards,\n",
        "    next_states,\n",
        "    is_done,\n",
        "    agent,\n",
        "    target_network,\n",
        "    gamma=0.99,\n",
        "    check_shapes=False,\n",
        "    device=None,\n",
        "    tensor_loss_evaluator=compute_td_loss_on_tensors_double,\n",
        "):\n",
        "    \"\"\"Вычисляет td-ошибку, используя только операции torch. Используйте формулы выше.\"\"\"\n",
        "\n",
        "    if device is None:\n",
        "        device = next(agent.parameters()).device\n",
        "    states = torch.tensor(\n",
        "        np.array(states), device=device, dtype=torch.uint8\n",
        "    )  # форма: [batch_size, *state_shape]\n",
        "    actions = torch.tensor(\n",
        "        actions, device=device, dtype=torch.int64\n",
        "    )  # форма: [batch_size]\n",
        "    rewards = torch.tensor(\n",
        "        rewards, device=device, dtype=torch.float32\n",
        "    )  # форма: [batch_size]\n",
        "    # форма: [batch_size, *state_shape]\n",
        "    next_states = torch.tensor(np.array(next_states), device=device, dtype=torch.uint8)\n",
        "    is_done = torch.tensor(\n",
        "        is_done, device=device, dtype=torch.bool\n",
        "    )  # форма: [batch_size]\n",
        "\n",
        "    return tensor_loss_evaluator(\n",
        "        states=states,\n",
        "        actions=actions,\n",
        "        rewards=rewards,\n",
        "        next_states=next_states,\n",
        "        is_done=is_done,\n",
        "        agent=agent,\n",
        "        target_network=target_network,\n",
        "        gamma=gamma,\n",
        "        check_shapes=check_shapes,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8AvquAtsoUG"
      },
      "source": [
        "Проверки на адекватность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nRoOn30soUG"
      },
      "outputs": [],
      "source": [
        "obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(10)\n",
        "\n",
        "loss = compute_td_loss(obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch,\n",
        "                       agent, target_network,\n",
        "                       gamma=0.99, check_shapes=True)\n",
        "loss.backward()\n",
        "\n",
        "assert loss.requires_grad and tuple(loss.data.size()) == (), \\\n",
        "    \"вы должны возвращать скалярную ошибку - среднее по батчу\"\n",
        "assert np.any(next(agent.parameters()).grad.data.cpu().numpy() != 0), \\\n",
        "    \"ошибка должна быть дифференцируемой по весам сети\"\n",
        "assert np.all(next(target_network.parameters()).grad is None), \\\n",
        "    \"целевая сеть не должна иметь градиентов\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIplL0hSsoUG"
      },
      "source": [
        "## Основной цикл (3 балла)\n",
        "\n",
        "Пришло время собрать все вместе и посмотреть, научится ли наш агент чему-нибудь.\n",
        "\n",
        "**Несколько хинтов:**\n",
        "При обучении агента можно менять:\n",
        "* различные гиперпараметры (размер буффера, batch size, lr и другие)\n",
        "* архитектуру нейросети (добавить больше внутренних весов/слоёв)\n",
        "\n",
        "При перезагрузке весов помните, что у вас теряется накопленный Experience Replay: в этом случае можно попробовать либо увеличить INITIAL_BUFFER_FILL, либо попробовать сохранять и подргужать сам Experience Replay с некоторым шагом (но это может занимать много памяти/времени)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JV-ulB-soUG"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import trange\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBzAAo-w5Z_O"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "### ВАШ КОД\n",
        "seed = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eurxA-_soUG"
      },
      "outputs": [],
      "source": [
        "env = make_final_env()\n",
        "\n",
        "state, _ = env.reset(seed=seed)\n",
        "\n",
        "agent = DQNAgent(\n",
        "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
        "    epsilon=1\n",
        ").to(device)\n",
        "target_network = DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS).to(device)\n",
        "target_network.load_state_dict(agent.q_network.state_dict())\n",
        "\n",
        "action_sampler = DqnActionSampler(agent)\n",
        "action_sampler_random = RandomActionSampler(env.action_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZg25kIasoUG"
      },
      "source": [
        "Буфер размером $10^4$ вероятно, сможет преодолеть порог для этого задания.\n",
        "\n",
        "Большие размеры ($10^5$ и $10^6$ являются обычным явлением) могут показать гораздо более высокий результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWyMxfN4soUG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from dqn.utils import is_enough_ram\n",
        "\n",
        "### Вы можете менять размер буффера. Если вы перезагружаете веса рекомендуется увеличить размер INITIAL_BUFFER_FILL\n",
        "REPLAY_BUFFER_SIZE = 10**6\n",
        "INITIAL_BUFFER_FILL = 50_000\n",
        "_n_steps = 100\n",
        "\n",
        "exp_replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
        "for i in trange(INITIAL_BUFFER_FILL // _n_steps):\n",
        "    if not is_enough_ram(min_available_gb=0.1):\n",
        "        print(\"\"\"\n",
        "            Доступно менее 100 МБ ОЗУ.\n",
        "            Убедитесь, что размер буфера не слишком большой.\n",
        "            Также проверьте, возможно, другие процессы сильно потребляют ОЗУ.\n",
        "            \"\"\"\n",
        "             )\n",
        "        break\n",
        "    _, state = play_and_record(state, action_sampler_random, env, exp_replay, n_steps=_n_steps)\n",
        "    if len(exp_replay) >= INITIAL_BUFFER_FILL:\n",
        "        break\n",
        "print(len(exp_replay))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHfIVpxG5Z_P"
      },
      "outputs": [],
      "source": [
        "len(exp_replay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ca9vbW4soUG"
      },
      "outputs": [],
      "source": [
        "### Вы можете попробовать поменять параметры при обучении и достичь более хороших результатов\n",
        "update_frequency = 4\n",
        "batch_size = 32\n",
        "total_steps = 10 * 10**6\n",
        "decay_steps = 10**6\n",
        "\n",
        "opt = torch.optim.Adam(agent.parameters(), lr=1e-4, eps=1.5e-4)\n",
        "\n",
        "init_epsilon = 1\n",
        "final_epsilon = 0.02\n",
        "\n",
        "loss_freq = 100\n",
        "refresh_target_network_freq = 10_000\n",
        "eval_freq = 10_000\n",
        "\n",
        "max_grad_norm = 10\n",
        "\n",
        "n_lives = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJWs0q-6soUG"
      },
      "outputs": [],
      "source": [
        "step = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "675-JU0hsoUG"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def wait_for_keyboard_interrupt():\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_2fgSxX5Z_Q"
      },
      "outputs": [],
      "source": [
        "from dqn.utils import linear_decay, is_enough_ram\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from dqn.logger import Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H572rIIk5Z_Q"
      },
      "outputs": [],
      "source": [
        "#use_tensorboard = True  #так можно наглядно посмотреть на процесс обучения\n",
        "use_tensorboard = False  #так быстрее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMdlRinu5Z_Q"
      },
      "outputs": [],
      "source": [
        "logger = Logger(use_tensorboard=use_tensorboard)\n",
        "\n",
        "if use_tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для сохранения прогресса обучения можно подключить гуглдиск и подгружать веса, если среда отключилась"
      ],
      "metadata": {
        "id": "-ZNMcNK9rbt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RELOAD_PROGRESS=True\n",
        "if 'google.colab' in sys.modules and RELOAD_PROGRESS:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zP_5x4pxrnEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules and RELOAD_PROGRESS:\n",
        "    # Создадим папку для сохранения, если её нет\n",
        "    model_save_path = '/content/drive/MyDrive/dqn_breakout/'\n",
        "    os.makedirs(model_save_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "D2on9vR0sOvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгружаем последний сохранённый чекпоинт"
      ],
      "metadata": {
        "id": "1rrh627essfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in sys.modules and RELOAD_PROGRESS:\n",
        "    checkpoint_path = '/content/drive/MyDrive/dqn_breakout/breakout_checkpoint.pth'\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "        agent.load_state_dict(checkpoint['agent_state_dict'])\n",
        "        opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Загружаем прогресс\n",
        "        step = checkpoint['step']\n",
        "        agent.epsilon = checkpoint['epsilon']\n",
        "\n",
        "        # Не забудьте также загрузить состояние в целевую сеть\n",
        "        target_network.load_state_dict(agent.q_network.state_dict())\n",
        "\n",
        "        print(f\"Модель и прогресс успешно загружены. Обучение будет продолжено с шага {step}.\")\n",
        "    else:\n",
        "        print(\"Сохранённая модель не найдена. Обучение начнется с нуля.\")"
      ],
      "metadata": {
        "id": "vPUNwgYfshFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps\n",
        "#refresh_target_network_freq"
      ],
      "metadata": {
        "id": "sUiBi8jls2MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgQ1vK3CsoUG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "env = make_final_env()\n",
        "state, _ = env.reset()\n",
        "\n",
        "with trange(step, total_steps + 1) as progress_bar:\n",
        "    for step in progress_bar:\n",
        "        if not is_enough_ram():\n",
        "            print('Доступно менее 100 МБ ОЗУ, приостановка.')\n",
        "            print('Убедитесь, что все в порядке, и используйте KeyboardInterrupt для продолжения.')\n",
        "            wait_for_keyboard_interrupt()\n",
        "\n",
        "        agent.epsilon = linear_decay(init_epsilon, final_epsilon, step, decay_steps)\n",
        "\n",
        "        # Играем\n",
        "        _, state = play_and_record(state, action_sampler, env, exp_replay, n_steps=update_frequency)\n",
        "\n",
        "        # Обучаем\n",
        "### ВАШ КОД\n",
        "        s, a, r, s_next, done = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "###ВАШ КОД: вычисляем функцию потерь\n",
        "        loss = ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "\n",
        "        loss.backward()\n",
        "        grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        if step % loss_freq == 0:\n",
        "            loss_value = loss.data.cpu().item()\n",
        "            grad_norm_value = grad_norm.cpu().item()\n",
        "            logger.log_loss(loss_value, step)\n",
        "            logger.log_grad_norm(grad_norm_value, step)\n",
        "\n",
        "        if step % refresh_target_network_freq == 0:\n",
        "            # Загружаем веса агента в целевую сеть\n",
        "###ВАШ КОД\n",
        "            ...\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ\n",
        "            torch.save(agent.state_dict(), \"last_state_dict.pt\")\n",
        "\n",
        "        if step % eval_freq == 0:\n",
        "            mean_reward = evaluate(\n",
        "                make_final_env(), agent, n_games=3 * n_lives, greedy=True, seed=step\n",
        "            )\n",
        "            initial_state_q_values = agent.get_qvalues(\n",
        "                [make_final_env().reset(seed=step)[0]]\n",
        "            )\n",
        "            initial_v = np.max(initial_state_q_values).item()\n",
        "\n",
        "            logger.log_mean_reward(mean_reward, step)\n",
        "            logger.log_initial_state_v(initial_v, step)\n",
        "\n",
        "            clear_output(True)\n",
        "            print(\"Размер буфера = %i, Эпсилон = %.5f\" % (len(exp_replay), agent.epsilon))\n",
        "\n",
        "            if not use_tensorboard:\n",
        "                logger.plot()\n",
        "        if 'google.colab' in sys.modules and RELOAD_PROGRESS and step%(refresh_target_network_freq/2)==0:\n",
        "          # Сохраняем состояние агента и оптимизатора\n",
        "          torch.save({\n",
        "              'agent_state_dict': agent.state_dict(),\n",
        "              'optimizer_state_dict': opt.state_dict(),\n",
        "              'step': step,  # Сохраняем текущий шаг\n",
        "              'epsilon': agent.epsilon,  # Сохраняем текущий эпсилон\n",
        "          }, os.path.join(model_save_path, 'breakout_checkpoint.pth'))\n",
        "\n",
        "          print(f\"Модель сохранена на шаге {step} в папку: {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewd5G-z05Z_Q"
      },
      "outputs": [],
      "source": [
        "agent = DQNAgent(\n",
        "    DQNetworkDueling(N_FRAMES_STACKED, N_ACTIONS),\n",
        "    epsilon=1\n",
        ").to(device)\n",
        "agent.load_state_dict(torch.load(\"last_state_dict.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Достижение агентом минимального порога (> 3) (3 балла)"
      ],
      "metadata": {
        "id": "BcaaBdopfIHK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEDQhQrdsoUG"
      },
      "source": [
        "Агент оценивается за 1 жизнь, а не за целый эпизод из 5 жизней. Награды в оценке также урезаны. Это сделано потому, что агент обучается именно в такой среде, и таким образом средние награды за жизнь можно сравнить со значением V для начального состояния.\n",
        "\n",
        "**Цель — набрать 15 очков в реальной среде**. Так что 3 или, лучше, 4 очка в предобработанной среде, вероятно, будет достаточно. После этого обучение можно прервать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0jLjYGwsoUG"
      },
      "source": [
        "Финальная оценка производится за весь эпизод со всеми 5 жизнями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTGVrwwQsoUG"
      },
      "outputs": [],
      "source": [
        "final_score = evaluate(\n",
        "  make_final_env(),\n",
        "    agent, n_games=30, greedy=True, t_max=10 * 1000, seed=9\n",
        ")\n",
        "print('финальный результат:', final_score)\n",
        "assert final_score >= 3, 'не так круто, как может DQN'\n",
        "print('Круто!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovaG8N4lsoUH"
      },
      "source": [
        "## Как интерпретировать графики:\n",
        "\n",
        "Это не обучение с учителем, поэтому не ожидайте, что что-то будет монотонно улучшаться.\n",
        "* **TD loss** — это MSE между текущими Q-значениями агента и целевыми Q-значениями. Она может медленно расти или падать, это нормально. «Ненормальное» поведение — это уход в NaN или застревание на нуле до того, как агент достигнет идеальной производительности.\n",
        "* **grad norm** — показывает интенсивность обучения. Ненормально — рост до значений около 100 (или даже 50), хотя это зависит от архитектуры сети.\n",
        "* **mean reward** — это ожидаемая сумма r(s,a), которую агент получает за полную игровую сессию. Она будет колебаться, но в среднем должна со временем расти (после нескольких тысяч итераций...).\n",
        " * В базовой реализации q-обучения требуется около 40 тыс. шагов для «разогрева» агента, прежде чем он начнет улучшаться.\n",
        "* **Initial state V** — это ожидаемая дисконтированная награда за эпизод по мнению агента. Она должна вести себя более гладко, чем **mean reward**. Со временем она должна расти, но иногда может испытывать просадки из-за переоценок агента.\n",
        "* **buffer size** — тут все просто. Он должен расти и достигать максимального размера.\n",
        "* **epsilon** — готовность агента исследовать. Если вы видите, что эпсилон уже на уровне 0.01, а средняя награда агента выше 0 — значит, нужно увеличить эпсилон. Установите его обратно на 0.2 - 0.5 и уменьшите скорость его снижения.\n",
        "* Сглаживание графиков выполняется с помощью гауссова ядра.\n",
        "\n",
        "Сначала ваш агент будет быстро проигрывать. Затем он научится проигрывать не так быстро и хотя бы несколько раз отбивать мяч. Наконец, он научится действительно набирать очки.\n",
        "\n",
        "**Обучение займет время.** На самом деле, много времени. Вероятно, вы не увидите никакого улучшения в течение первых **150 тыс.** временных шагов (обратите внимание, что по умолчанию в этом ноутбуке агент оценивается каждые 5000 шагов).\n",
        "\n",
        "Но долгое время обучения не так уж и плохо:)\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/training.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVV72AB-soUH"
      },
      "source": [
        "## О гиперпараметрах:\n",
        "\n",
        "Эта задача имеет что-то общее с обучением с учителем: ошибка оптимизируется через буфер (вместо обучающего набора данных). Но распределение состояний и действий в буфере **не стационарно** и зависит от политики, которая его сгенерировала. Может даже случиться так, что средняя TD-ошибка по буферу очень низкая, но производительность крайне плохая (представьте, что агент, собирая данные в буфер, всегда умудряется избегать мяча).\n",
        "\n",
        "* **Общее количество шагов и время обучения:** Кажется, что это очень много, но на самом деле для RL это нормально.\n",
        "\n",
        "* **Расписание затухания $\\epsilon$** было взято из оригинальной статьи и является традиционным для эпсилон-жадных политик. В начале обучения жадная политика агента слаба, поэтому следует совершать много случайных действий.\n",
        "\n",
        "* **Оптимизатор:** В оригинальной статье использовался RMSProp (в 2013 году у них не было Adam), и он может работать не хуже Adam. Для нас Adam был по умолчанию, и он сработал.\n",
        "\n",
        "* **lr:** $10^{-3}$, вероятно, будет слишком большим.\n",
        "\n",
        "* **Частота обновления целевой сети:** имеет что-то общее с learning rate. Слишком частые обновления могут привести к расхождению. Слишком редкие — к медленному обучению. Для миллионов общих шагов тысячи внутренних шагов кажутся нормальными. Одна итерация обновления целевой сети — это итерация (на этот раз аппроксимационной) $\\gamma$-свертки, которая лежит в основе Q-обучения. Чем больше внутренних шагов, тем точнее свертка."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plp8WC_esoUH"
      },
      "source": [
        "## Видео"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdExc_AssoUH"
      },
      "outputs": [],
      "source": [
        "# запись сессий\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with make_final_env() as env, RecordVideo(\n",
        "    env=env, video_folder=\"./videos\", episode_trigger=lambda episode_number: True\n",
        ") as env_monitor:\n",
        "    sessions = [\n",
        "        evaluate(env_monitor, agent, n_games=n_lives, greedy=True) for _ in range(10)\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt6xg1n_soUH"
      },
      "outputs": [],
      "source": [
        "# Показать видео. Это может не работать в некоторых конфигурациях. Если у вас\n",
        "# не работает, вы можете скачать видео и посмотреть их локально.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b6encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # Вы также можете попробовать другие индексы\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b6encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLPx2aI7soUH"
      },
      "source": [
        "## Давайте посмотрим на это поближе. Интерпретация (2 балла).\n",
        "\n",
        "Давайте сыграем 5 эпизодов (обратите внимание, что в игре 5 жизней) и запишем некоторую статистику:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRaIHfxQ5Z_R"
      },
      "outputs": [],
      "source": [
        "from dqn.analysis import play_and_log_episode\n",
        "\n",
        "env = make_final_env()\n",
        "stats = play_and_log_episode(env, agent)\n",
        "\n",
        "print(\"Ключи:\", list(stats.keys()))\n",
        "print(\"Формы:\")\n",
        "for key in [\"states\", \"qvalues\", \"actions\", \"rewards\"]:\n",
        "    print(f\"{key}: {stats[key].shape}\")\n",
        "print(\"завершено:\", stats[\"episode_finished\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B-q_ztF5Z_R"
      },
      "source": [
        "Построим график наград:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBGD3EzL5Z_S"
      },
      "outputs": [],
      "source": [
        "plt.plot(stats[\"rewards\"])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoNrLrJJ5Z_S"
      },
      "source": [
        "Ваша задача — оценить следующие величины из логов:\n",
        "1. Дисконтированные доходы: $G[t] = \\sum_{t'=t}^T \\gamma ^ {t' - t}r[t]$, где $T$ — общее время эпизода.\n",
        "2. Ценности состояний, оцененные агентом: $V_{agent}[t] = \\max_{a}Q_{agent}(s[t], a)$.\n",
        "3. Разброс Q-значений: $\\Delta Q[t] = \\max_{a}Q_{agent}(s[t], a) - \\min_{a}Q_{agent}(s[t], a)$\n",
        "\n",
        "Создайте новую среду: `env = make_final_env()`, сыграйте 5 эпизодов (полная игра имеет 5 жизней, так что это будет 1 полная игра).\n",
        "Постройте графики наград и оцененных величин для каждого из них.\n",
        "Используя графики, можете ли вы найти моменты, когда мяч ударяется о стену?\n",
        "Когда мяч ударяется о платформу?\n",
        "Вероятно, вам не понадобятся все эти величины для этого, но все же хорошо проверить поведение модели.\n",
        "\n",
        "Функция `merge_frame_stack_to_plot` может быть полезна."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLplnNKG5Z_S"
      },
      "outputs": [],
      "source": [
        "def get_discounted_returns(rewards: Reversible[float], gamma: float) -> list[float]:\n",
        "    \"\"\"\n",
        "    Вычисляет G[t] для каждого t, учитывая награды и гамму.\n",
        "\n",
        "    Совет: Итерируйте в обратном порядке по наградам и используйте следующее соотношение:\n",
        "    G[t] = r[t] + gamma * G[t + 1]\n",
        "    \"\"\"\n",
        "### ВАШ КОД\n",
        "    ...\n",
        "    return returns\n",
        "###ВАШ КОД ЗАКОНЧИЛСЯ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dqn.analysis import play_and_log_episode\n",
        "\n",
        "eval_env = make_final_env()\n",
        "record = play_and_log_episode(eval_env, agent)\n",
        "print('общая награда за эпизод:', np.sum(record['rewards']))\n",
        "for key in record:\n",
        "    print(key)"
      ],
      "metadata": {
        "id": "WxQJxyN5gB-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# Вычисляем V-значения по Монте-Карло и по агенту\n",
        "v_mc = get_discounted_returns(record['rewards'], 0.99)#np.array([np.sum(record['rewards'][i:] * (0.99 ** np.arange(len(record['rewards']) - i)))\n",
        "#                 for i in range(len(record['rewards']))])\n",
        "v_agent = np.max(record['qvalues'], axis=1)\n",
        "\n",
        "ax.scatter(v_mc, v_agent)\n",
        "ax.plot(sorted(v_mc), sorted(v_mc),\n",
        "       'black', linestyle='--', label='x=y')\n",
        "\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "ax.set_title('Оценки ценности состояний')\n",
        "ax.set_xlabel('Монте-Карло')\n",
        "ax.set_ylabel('Агент')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHyCStMwgLHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ВАШ код для того, чтобы сыграть 5 эпизодов и проанализировать их"
      ],
      "metadata": {
        "id": "AvRwxKQ5lFNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e36bU0u8soUH"
      },
      "source": [
        "## Бонус I (4 балла). Получите высокий результат!\n",
        "\n",
        "Получите среднюю награду за жизнь:\n",
        "1. $\\geq 20$: +2 балл\n",
        "2. $\\geq 40$: +2 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78e4nRoSsoUH"
      },
      "source": [
        "## Бонус II (8 баллов). Примените модификации к DQN.\n",
        "\n",
        "* [Prioritized experience replay](https://arxiv.org/abs/1511.05952) (2 балла, пожалуйста, проверьте наличие эффективных реализаций с открытым исходным кодом)\n",
        "* [Noisy Nets](https://arxiv.org/abs/1706.10295) (2 балла, пожалуйста, обратите внимание на политику исследования и используется ли эпсилон-жадная политика)\n",
        "* [Distributional RL](https://arxiv.org/abs/1707.06887) (distributional и distributed здесь означают разные вещи) (2 балла)\n",
        "* Другие модификации (2 балла), например Распределенное RL.\n",
        "https://gymnasium.farama.org/api/vector/#gymnasium.vector.AsyncVectorEnv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}