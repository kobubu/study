{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b67c89-0a76-4222-8e85-e6360c918966",
   "metadata": {},
   "source": [
    "# Auto sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc09ba3-409a-47e9-96eb-062b3b48f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn\n",
      "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
      "     ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/6.5 MB 660.6 kB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.2/6.5 MB 2.8 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.7/6.5 MB 5.5 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.0/6.5 MB 6.6 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.1/6.5 MB 4.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.6/6.5 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 2.1/6.5 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.1/6.5 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 2.7/6.5 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.1/6.5 MB 7.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.5/6.5 MB 7.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.1/6.5 MB 7.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.4/6.5 MB 7.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.9/6.5 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 5.2/6.5 MB 8.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.8/6.5 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.3/6.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.5/6.5 MB 7.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"F:\\Anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"F:\\Anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"F:\\Anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\NeKonn\\AppData\\Local\\Temp\\pip-build-env-_02cs9r3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\NeKonn\\AppData\\Local\\Temp\\pip-build-env-_02cs9r3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 301, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\NeKonn\\AppData\\Local\\Temp\\pip-build-env-_02cs9r3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\NeKonn\\AppData\\Local\\Temp\\pip-build-env-_02cs9r3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 10, in <module>\n",
      "  ValueError: Detected unsupported operating system: win32. Please check the compability information of auto-sklearn: https://automl.github.io/auto-sklearn/master/installation.html#windows-osx-compatibility\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2c0255-bb0e-41d6-b5b0-3bc0c3b8335e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautosklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Создание и обучение Auto-sklearn классификатора\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,  # Ограничение времени в секундах\n",
    "    per_run_time_limit=30,        # Макс. время на одну модель\n",
    "    n_jobs=-1,                    # Использовать все ядра\n",
    ")\n",
    "automl.fit(X_train, y_train, dataset_name='breast_cancer')\n",
    "\n",
    "# Предсказание и оценка\n",
    "y_pred = automl.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Просмотр лучших моделей\n",
    "print(automl.leaderboard())\n",
    "print(automl.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5312a05-df20-426f-94f8-e63b55e72d98",
   "metadata": {},
   "source": [
    "# Flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670ca7fd-b8da-415c-9855-eded980475c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flaml\n",
      "  Downloading FLAML-2.3.6-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: NumPy>=1.17 in f:\\anaconda\\lib\\site-packages (from flaml) (1.26.4)\n",
      "Downloading FLAML-2.3.6-py3-none-any.whl (322 kB)\n",
      "   ---------------------------------------- 0.0/322.2 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 61.4/322.2 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 307.2/322.2 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 322.2/322.2 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: flaml\n",
      "Successfully installed flaml-2.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3284309f-177d-4e83-897d-e109e880ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in f:\\anaconda\\lib\\site-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in f:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in f:\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in f:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.9 MB 1.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/8.9 MB 3.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/8.9 MB 6.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.9 MB 7.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.9/8.9 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.0/8.9 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/8.9 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/8.9 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.6/8.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.2/8.9 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.7/8.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.3/8.9 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.4/8.9 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.5/8.9 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 10.7 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n",
      "Successfully installed scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d38b951-c926-4738-b7c4-2152f4548704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-19 11:48:11] {1752} INFO - task = classification\n",
      "[flaml.automl.logger: 09-19 11:48:11] {1763} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 09-19 11:48:11] {1862} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 09-19 11:48:11] {1979} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'catboost', 'lrl1']\n",
      "[flaml.automl.logger: 09-19 11:48:11] {2282} INFO - iteration 0, current learner lgbm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 21\u001b[0m\n\u001b[0;32m     12\u001b[0m automl_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_budget\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m60\u001b[39m,   \u001b[38;5;66;03m# Общее время поиска в секундах\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Метрика для оптимизации\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_file_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflaml_log.log\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m automl\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m=\u001b[39mX_train, y_train\u001b[38;5;241m=\u001b[39my_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mautoml_settings)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Предсказание и вывод результатов\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛучшая метрика на валидации:\u001b[39m\u001b[38;5;124m\"\u001b[39m, automl\u001b[38;5;241m.\u001b[39mbest_loss)\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\automl.py:2004\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[1;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, mlflow_exp_name, **fit_kwargs)\u001b[0m\n\u001b[0;32m   2002\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m training_log_writer(log_file_name, append_log) \u001b[38;5;28;01mas\u001b[39;00m save_helper:\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m save_helper\n\u001b[1;32m-> 2004\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search()\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\automl.py:2572\u001b[0m, in \u001b[0;36mAutoML._search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2566\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlflow_integration\u001b[38;5;241m.\u001b[39mrecord_state(\n\u001b[0;32m   2567\u001b[0m             automl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2568\u001b[0m             search_state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[0;32m   2569\u001b[0m             estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   2570\u001b[0m         )\n\u001b[0;32m   2571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m-> 2572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_sequential()\n\u001b[0;32m   2573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\automl.py:2382\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2376\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[0;32m   2377\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2378\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2379\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m   2380\u001b[0m         )\n\u001b[0;32m   2381\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 2382\u001b[0m analysis \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2383\u001b[0m     search_state\u001b[38;5;241m.\u001b[39mtraining_function,\n\u001b[0;32m   2384\u001b[0m     search_alg\u001b[38;5;241m=\u001b[39msearch_state\u001b[38;5;241m.\u001b[39msearch_alg,\n\u001b[0;32m   2385\u001b[0m     time_budget_s\u001b[38;5;241m=\u001b[39mtime_budget_s,\n\u001b[0;32m   2386\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   2387\u001b[0m     use_ray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2388\u001b[0m     use_spark\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2389\u001b[0m     force_cancel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_cancel,\n\u001b[0;32m   2390\u001b[0m     mlflow_exp_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mlflow_exp_name,\n\u001b[0;32m   2391\u001b[0m     automl_info\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,),  \u001b[38;5;66;03m# pass automl info to tune.run\u001b[39;00m\n\u001b[0;32m   2392\u001b[0m     extra_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautolog_extra_tag,\n\u001b[0;32m   2393\u001b[0m )\n\u001b[0;32m   2394\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[0;32m   2395\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\tune\\tune.py:894\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, mlflow_exp_name, automl_info, extra_tag, cost_attr, cost_budget, **ray_args)\u001b[0m\n\u001b[0;32m    892\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[1;32m--> 894\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluation_function(trial_to_run\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    895\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in tune: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_to_run\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\state.py:306\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[1;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m )\n\u001b[0;32m    300\u001b[0m (\n\u001b[0;32m    301\u001b[0m     trained_estimator,\n\u001b[0;32m    302\u001b[0m     val_loss,\n\u001b[0;32m    303\u001b[0m     metric_for_logging,\n\u001b[0;32m    304\u001b[0m     _,\n\u001b[0;32m    305\u001b[0m     pred_time,\n\u001b[1;32m--> 306\u001b[0m ) \u001b[38;5;241m=\u001b[39m compute_estimator(\n\u001b[0;32m    307\u001b[0m     sampled_X_train,\n\u001b[0;32m    308\u001b[0m     sampled_y_train,\n\u001b[0;32m    309\u001b[0m     state\u001b[38;5;241m.\u001b[39mX_val,\n\u001b[0;32m    310\u001b[0m     state\u001b[38;5;241m.\u001b[39my_val,\n\u001b[0;32m    311\u001b[0m     state\u001b[38;5;241m.\u001b[39mweight_val,\n\u001b[0;32m    312\u001b[0m     state\u001b[38;5;241m.\u001b[39mgroups_val,\n\u001b[0;32m    313\u001b[0m     state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;28;01mif\u001b[39;00m budget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(budget, state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf),\n\u001b[0;32m    314\u001b[0m     state\u001b[38;5;241m.\u001b[39mkf,\n\u001b[0;32m    315\u001b[0m     config,\n\u001b[0;32m    316\u001b[0m     state\u001b[38;5;241m.\u001b[39mtask,\n\u001b[0;32m    317\u001b[0m     estimator,\n\u001b[0;32m    318\u001b[0m     state\u001b[38;5;241m.\u001b[39meval_method,\n\u001b[0;32m    319\u001b[0m     state\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    320\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m    321\u001b[0m     state\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    322\u001b[0m     state\u001b[38;5;241m.\u001b[39mlearner_classes\u001b[38;5;241m.\u001b[39mget(estimator),\n\u001b[0;32m    323\u001b[0m     state\u001b[38;5;241m.\u001b[39mcv_score_agg_func,\n\u001b[0;32m    324\u001b[0m     state\u001b[38;5;241m.\u001b[39mlog_training_metric,\n\u001b[0;32m    325\u001b[0m     this_estimator_kwargs,\n\u001b[0;32m    326\u001b[0m     state\u001b[38;5;241m.\u001b[39mfree_mem_ratio,\n\u001b[0;32m    327\u001b[0m )\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[0;32m    329\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\ml.py:382\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[1;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    364\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[0;32m    365\u001b[0m         config_dic,\n\u001b[0;32m    366\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate_model_CV(\n\u001b[0;32m    383\u001b[0m         config_dic,\n\u001b[0;32m    384\u001b[0m         estimator,\n\u001b[0;32m    385\u001b[0m         X_train,\n\u001b[0;32m    386\u001b[0m         y_train,\n\u001b[0;32m    387\u001b[0m         budget,\n\u001b[0;32m    388\u001b[0m         kf,\n\u001b[0;32m    389\u001b[0m         eval_metric,\n\u001b[0;32m    390\u001b[0m         best_val_loss,\n\u001b[0;32m    391\u001b[0m         cv_score_agg_func,\n\u001b[0;32m    392\u001b[0m         log_training_metric\u001b[38;5;241m=\u001b[39mlog_training_metric,\n\u001b[0;32m    393\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    394\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, TransformersEstimator):\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\task\\generic_task.py:788\u001b[0m, in \u001b[0;36mGenericTask.evaluate_model_CV\u001b[1;34m(self, config, estimator, X_train_all, y_train_all, budget, kf, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    785\u001b[0m         groups_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    787\u001b[0m estimator\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m--> 788\u001b[0m val_loss_i, metric_i, train_time_i, pred_time_i \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[0;32m    789\u001b[0m     config,\n\u001b[0;32m    790\u001b[0m     estimator,\n\u001b[0;32m    791\u001b[0m     X_train,\n\u001b[0;32m    792\u001b[0m     y_train,\n\u001b[0;32m    793\u001b[0m     X_val,\n\u001b[0;32m    794\u001b[0m     y_val,\n\u001b[0;32m    795\u001b[0m     weight_val,\n\u001b[0;32m    796\u001b[0m     groups_val,\n\u001b[0;32m    797\u001b[0m     eval_metric,\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    799\u001b[0m     labels,\n\u001b[0;32m    800\u001b[0m     budget_per_train,\n\u001b[0;32m    801\u001b[0m     log_training_metric\u001b[38;5;241m=\u001b[39mlog_training_metric,\n\u001b[0;32m    802\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    803\u001b[0m     free_mem_ratio\u001b[38;5;241m=\u001b[39mfree_mem_ratio,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric_i, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m metric_i\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m metric_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\ml.py:516\u001b[0m, in \u001b[0;36mget_val_loss\u001b[1;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, task, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    511\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['groups_val'] = groups_val\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['X_val'] = X_val\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['y_val'] = y_val\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, budget\u001b[38;5;241m=\u001b[39mbudget, free_mem_ratio\u001b[38;5;241m=\u001b[39mfree_mem_ratio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    517\u001b[0m val_loss, metric_for_logging, pred_time, _ \u001b[38;5;241m=\u001b[39m _eval_estimator(\n\u001b[0;32m    518\u001b[0m     config,\n\u001b[0;32m    519\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m     fit_kwargs,\n\u001b[0;32m    531\u001b[0m )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\model.py:1597\u001b[0m, in \u001b[0;36mLGBMEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mset_params(callbacks\u001b[38;5;241m=\u001b[39mcallbacks[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X_train, y_train, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1598\u001b[0m best_iteration \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mget_booster(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, XGBoostSklearnEstimator)\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mbest_iteration_\n\u001b[0;32m   1602\u001b[0m )\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_iteration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m best_iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\flaml\\automl\\model.py:241\u001b[0m, in \u001b[0;36mBaseEstimator._fit\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;66;03m# groups_val = kwargs.get('groups_val')\u001b[39;00m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m#     kwargs['eval_group'] = [group_counts(groups_val)]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m#     kwargs['verbose'] = False\u001b[39;00m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m#     del kwargs['groups_val'], kwargs['X_val'], kwargs['y_val']\u001b[39;00m\n\u001b[0;32m    240\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(X_train)\n\u001b[1;32m--> 241\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# xgboost 1.6 doesn't display all the params in the model str\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaml.automl.model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit started with params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Инициализация и настройка AutoML\n",
    "automl = AutoML()\n",
    "# Настройки времени поиска\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60,   # Общее время поиска в секундах\n",
    "    \"metric\": 'accuracy', # Метрика для оптимизации\n",
    "    \"task\": 'classification',\n",
    "    \"n_jobs\": -1,\n",
    "    \"log_file_name\": 'flaml_log.log'\n",
    "}\n",
    "\n",
    "# Обучение\n",
    "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
    "\n",
    "# Предсказание и вывод результатов\n",
    "print(\"Лучшая метрика на валидации:\", automl.best_loss)\n",
    "print(\"Лучший шаг пайплайна:\", automl.best_config)\n",
    "print(\"Accuracy на тесте:\", automl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b486a-9af3-4fae-b6ae-89ed350b9df7",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62f878eb-7a8c-41fa-a139-7380b5ce4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-1.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.4 in f:\\anaconda\\lib\\site-packages (from tpot) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in f:\\anaconda\\lib\\site-packages (from tpot) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in f:\\anaconda\\lib\\site-packages (from tpot) (1.7.2)\n",
      "Collecting update-checker>=0.16 (from tpot)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in f:\\anaconda\\lib\\site-packages (from tpot) (4.65.0)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pandas>=2.2.0 (from tpot)\n",
      "  Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\anaconda\\lib\\site-packages (from tpot) (1.2.0)\n",
      "Collecting xgboost>=3.0.0 (from tpot)\n",
      "  Downloading xgboost-3.0.5-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: matplotlib>=3.6.2 in f:\\anaconda\\lib\\site-packages (from tpot) (3.8.0)\n",
      "Collecting traitlets>=5.8.0 (from tpot)\n",
      "  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lightgbm>=3.3.3 (from tpot)\n",
      "  Using cached lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting optuna>=3.0.5 (from tpot)\n",
      "  Using cached optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in f:\\anaconda\\lib\\site-packages (from tpot) (3.1)\n",
      "Collecting dask>=2024.4.2 (from tpot)\n",
      "  Downloading dask-2025.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting distributed>=2024.4.2 (from tpot)\n",
      "  Downloading distributed-2025.9.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting dask-expr>=1.0.12 (from tpot)\n",
      "  Downloading dask_expr-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting dask-jobqueue>=0.8.5 (from tpot)\n",
      "  Downloading dask_jobqueue-0.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting func-timeout>=4.3.5 (from tpot)\n",
      "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
      "     ---------------------------------------- 0.0/44.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.3/44.3 kB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting configspace>=1.1.1 (from tpot)\n",
      "  Downloading configspace-1.2.1.tar.gz (130 kB)\n",
      "     ---------------------------------------- 0.0/131.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 131.0/131.0 kB 3.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dill>=0.3.9 (from tpot)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting seaborn>=0.13.2 (from tpot)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyparsing in f:\\anaconda\\lib\\site-packages (from configspace>=1.1.1->tpot) (3.0.9)\n",
      "Requirement already satisfied: typing_extensions in f:\\anaconda\\lib\\site-packages (from configspace>=1.1.1->tpot) (4.12.2)\n",
      "Requirement already satisfied: more_itertools in f:\\anaconda\\lib\\site-packages (from configspace>=1.1.1->tpot) (10.1.0)\n",
      "Requirement already satisfied: click>=8.1 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (8.2.1)\n",
      "Collecting cloudpickle>=3.0.0 (from dask>=2024.4.2->tpot)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (23.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (0.12.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in f:\\anaconda\\lib\\site-packages (from dask>=2024.4.2->tpot) (7.0.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (3.1.3)\n",
      "Requirement already satisfied: locket>=1.0.0 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (1.0.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (5.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (2.0.7)\n",
      "Requirement already satisfied: zict>=3.0.0 in f:\\anaconda\\lib\\site-packages (from distributed>=2024.4.2->tpot) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\anaconda\\lib\\site-packages (from matplotlib>=3.6.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in f:\\anaconda\\lib\\site-packages (from optuna>=3.0.5->tpot) (1.13.3)\n",
      "Collecting colorlog (from optuna>=3.0.5->tpot)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in f:\\anaconda\\lib\\site-packages (from optuna>=3.0.5->tpot) (2.0.25)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\anaconda\\lib\\site-packages (from pandas>=2.2.0->tpot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\anaconda\\lib\\site-packages (from pandas>=2.2.0->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\anaconda\\lib\\site-packages (from scikit-learn>=1.6->tpot) (3.6.0)\n",
      "Requirement already satisfied: colorama in f:\\anaconda\\lib\\site-packages (from tqdm>=4.36.1->tpot) (0.4.6)\n",
      "Requirement already satisfied: requests>=2.3.0 in f:\\anaconda\\lib\\site-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
      "Requirement already satisfied: Mako in f:\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.0.5->tpot) (1.3.5)\n",
      "Requirement already satisfied: zipp>=0.5 in f:\\anaconda\\lib\\site-packages (from importlib_metadata>=4.13.0->dask>=2024.4.2->tpot) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\anaconda\\lib\\site-packages (from jinja2>=2.10.3->distributed>=2024.4.2->tpot) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in f:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in f:\\anaconda\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna>=3.0.5->tpot) (3.0.1)\n",
      "Downloading TPOT-1.1.0-py3-none-any.whl (215 kB)\n",
      "   ---------------------------------------- 0.0/215.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 215.1/215.1 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading dask-2025.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.5 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading dask_expr-2.0.0-py3-none-any.whl (3.2 kB)\n",
      "Downloading dask_jobqueue-0.9.0-py2.py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.0/52.0 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "   ---------------------------------------- 0.0/119.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 119.7/119.7 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading distributed-2025.9.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.5/1.0 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 10.6 MB/s eta 0:00:00\n",
      "Using cached lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Using cached optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.3 MB 11.1 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.1/11.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.6/11.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.3 MB 11.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/11.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.4/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.9/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.5/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.8/11.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.3/11.3 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.9/11.3 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 11.5 MB/s eta 0:00:00\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading xgboost-3.0.5-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/56.8 MB 16.8 MB/s eta 0:00:04\n",
      "    --------------------------------------- 1.1/56.8 MB 13.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.6/56.8 MB 12.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 2.2/56.8 MB 12.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 2.7/56.8 MB 12.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.2/56.8 MB 12.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.8/56.8 MB 12.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.3/56.8 MB 12.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.9/56.8 MB 12.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 5.5/56.8 MB 12.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.0/56.8 MB 12.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.5/56.8 MB 11.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 7.1/56.8 MB 11.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 7.6/56.8 MB 11.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 8.2/56.8 MB 11.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 8.7/56.8 MB 11.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 9.2/56.8 MB 11.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 9.8/56.8 MB 11.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 10.3/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 10.9/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 11.4/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 11.9/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 12.5/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 13.0/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 13.6/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 14.1/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 14.7/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 15.2/56.8 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 16.3/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 16.8/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 17.4/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 17.9/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 18.4/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 19.0/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 19.5/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 20.1/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 20.6/56.8 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 21.1/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 21.7/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 22.2/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 22.8/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 23.3/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 23.8/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 24.4/56.8 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 24.9/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 25.5/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 26.0/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 26.6/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 27.1/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 27.7/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 28.2/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 28.7/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 29.3/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 29.8/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 30.4/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 30.9/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 31.5/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 32.0/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 32.6/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 33.1/56.8 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 33.6/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 34.2/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 34.7/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 35.3/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 35.8/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 36.4/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 36.9/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 37.4/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 38.0/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 38.5/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 39.1/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 39.6/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 40.1/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 40.7/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 41.2/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 41.8/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 42.3/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 42.9/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 43.4/56.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 44.0/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 44.5/56.8 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 45.0/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 45.6/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 46.1/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 46.7/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 47.2/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 47.8/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 48.3/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 48.9/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 49.4/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 49.9/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 50.5/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 51.0/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 51.6/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 52.1/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 52.6/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.2/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.7/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.3/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.9/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.4/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.9/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.5/56.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.8/56.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 11.1 MB/s eta 0:00:00\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: configspace, func-timeout, stopit\n",
      "  Building wheel for configspace (pyproject.toml): started\n",
      "  Building wheel for configspace (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for configspace: filename=configspace-1.2.1-py3-none-any.whl size=116016 sha256=ef20869724906610cf29fce2e7e1aaf86fb4b72091cbc264e36c480c5db9bf2a\n",
      "  Stored in directory: c:\\users\\nekonn\\appdata\\local\\pip\\cache\\wheels\\11\\0f\\36\\d5027c3eeb038827889830f7efbe6a1bad8956b3eb44ab2f44\n",
      "  Building wheel for func-timeout (setup.py): started\n",
      "  Building wheel for func-timeout (setup.py): finished with status 'done'\n",
      "  Created wheel for func-timeout: filename=func_timeout-4.3.5-py3-none-any.whl size=15109 sha256=a076a2ecf5cb32d657e50fc08ae907c85a13bc34012e75672bf135b3d43c3071\n",
      "  Stored in directory: c:\\users\\nekonn\\appdata\\local\\pip\\cache\\wheels\\07\\e6\\86\\f23164d12c3134966614102db8e7956ab359faf7ffd78703ce\n",
      "  Building wheel for stopit (setup.py): started\n",
      "  Building wheel for stopit (setup.py): finished with status 'done'\n",
      "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=12020 sha256=b9269b41b49a23239f803996688bf9fd1918696eeeb00dacfa05e9e7dd732253\n",
      "  Stored in directory: c:\\users\\nekonn\\appdata\\local\\pip\\cache\\wheels\\da\\77\\2d\\adbc56bc4db95ad80c6d4e71cd69e2d9d122174904342e3f7f\n",
      "Successfully built configspace func-timeout stopit\n",
      "Installing collected packages: stopit, func-timeout, traitlets, dill, colorlog, cloudpickle, xgboost, update-checker, pandas, lightgbm, dask, configspace, seaborn, optuna, distributed, dask-expr, dask-jobqueue, tpot\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.7.1\n",
      "    Uninstalling traitlets-5.7.1:\n",
      "      Successfully uninstalled traitlets-5.7.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.1\n",
      "    Uninstalling cloudpickle-2.2.1:\n",
      "      Successfully uninstalled cloudpickle-2.2.1\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 2.1.2\n",
      "    Uninstalling xgboost-2.1.2:\n",
      "      Successfully uninstalled xgboost-2.1.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2023.11.0\n",
      "    Uninstalling dask-2023.11.0:\n",
      "      Successfully uninstalled dask-2023.11.0\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2023.11.0\n",
      "    Uninstalling distributed-2023.11.0:\n",
      "      Successfully uninstalled distributed-2023.11.0\n",
      "Successfully installed cloudpickle-3.1.1 colorlog-6.9.0 configspace-1.2.1 dask-2025.9.1 dask-expr-2.0.0 dask-jobqueue-0.9.0 dill-0.4.0 distributed-2025.9.1 func-timeout-4.3.5 lightgbm-4.6.0 optuna-4.5.0 pandas-2.3.2 seaborn-0.13.2 stopit-1.1.2 tpot-1.1.0 traitlets-5.14.3 update-checker-0.18.0 xgboost-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'F:\\Anaconda\\Lib\\site-packages\\~gboost'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "great-expectations 1.5.11 requires pandas<2.2,>=1.3.0; python_version >= \"3.10\", but you have pandas 2.3.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e8f7e18-c157-4a76-abe6-d346a85e975f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_tags' from 'sklearn.utils._tags' (F:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_tags.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtpot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TPOTClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_digits\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\tpot\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#TODO: are all the imports in the init files done correctly?\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#TODO clean up import organization\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindividual\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseIndividual\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphsklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphPipeline\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Population\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builtin_modules\n",
      "File \u001b[1;32mF:\\Anaconda\\Lib\\site-packages\\tpot\\graphsklearn.py:51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_classifier, is_regressor\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tags\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#labels - str\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#attributes - \"instance\" -> instance of the type\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_tags' from 'sklearn.utils._tags' (F:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_tags.py)"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_digits_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
